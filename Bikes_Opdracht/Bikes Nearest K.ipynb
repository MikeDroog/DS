{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bikes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier een jupyter notebook bestand waar jullie in kunnen werken. Denk aan het lesmateriaal van afgelopen middag. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stel je een casus voor. Een fietsenmakerbedrijf heeft moeite met de verkoop van fietsen aan zijn of haar klanten en doet wanhopige pogingen om klanten te lokken bij zijn bedrijf. Er zijn gewoon te veel factoren voor de fietsenmaker om te voorspellen wie je moet bereiken. Hij besluit een datascientist in te huren die in één dag tijd uit zijn data bruikbare informatie probeert te halen.  Dit kan op enkele manieren, namelijk, door (i) inzicht te geven in de relaties tussen attributen in de dataset, (ii) deze relaties te visualiseren, (iii) te laten zien welke attributen (features) van belang zijn voor het voorspellen van een potentiele klant en (iv) hoe goed een model kan voorspellen wie van een nieuwe test-set klanten wel of niet een fiets gaat kopen. \n",
    " \n",
    "Presenteer je bevindingen en proces in een verslag. Dit mag in een jupyter notebook bestand of in een word-bestand. Je mag bij deze opdracht gebruik maken van WEKA en van PYTHON (en natuurlijk jupyter notebook). Hou de volgende structuur aan in je verslag:  \n",
    " \n",
    "Weka leent zich goed voor om de data te importeren en snel in te zien. Verschillende relaties te herkennen en algoritmes snel op toe te passen.  \n",
    " \n",
    "Python leent zich goed voor het verkennen en aanpassen van de data. Er missen hier en daar waardes die opgevuld dienen te worden.  \n",
    " \n",
    "Beoordeling \n",
    " \n",
    "Je wordt bij deze opdracht beoordeeld op de volgende criteria:  \n",
    " \n",
    "1. De navolgbaarheid van je proces. Als opdrachtgever wil je het proces kunnen begrijpen van je datascientist. Waarom heeft hij/zij deze en deze keuze gemaakt? Wat voegt het toe aan de wens van de opdrachtgever? \n",
    "2. Is de data voldoende geïnterpreteerd en uitgelegd? Leg bijvoorbeeld per attribuut uit of het een (grote) rol speelt voor het voorspellen van het wel of niet kopen van een fiets. Kijk of je een plot kan maken van de data (wij de docenten zullen hier morgen ondersteuning voor geven).  \n",
    "3. Heb je kunnen voorspellen wie er van de test-set een fiets heeft gekocht of niet. We zullen hier niet streng op zijn sinds het concept hiervan nog vrij lastig is. De voorspelling mag zowel met WEKA als met PYTHON gemaakt worden. Nog beter als je het met beide doet. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll start with importing the csv and looking at the contents of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bikes = pd.read_csv('bikes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      "ID                  1000 non-null int64\n",
      "Marital Status      1000 non-null object\n",
      "Gender              1000 non-null object\n",
      "Income              932 non-null float64\n",
      "Children            1000 non-null int64\n",
      "Education           1000 non-null object\n",
      "Occupation          1000 non-null object\n",
      "Home Owner          1000 non-null object\n",
      "Cars                1000 non-null int64\n",
      "Commute Distance    1000 non-null object\n",
      "Region              995 non-null object\n",
      "Age                 989 non-null float64\n",
      "Purchased Bike      1000 non-null object\n",
      "dtypes: float64(2), int64(3), object(8)\n",
      "memory usage: 101.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Purchased Bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12496</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24107</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14177</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24381</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25597</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Yes                                           ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>23731</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>54.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>28672</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>11809</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>19664</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Management</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>12121</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>10+ Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>53.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Marital Status  Gender    Income  Children        Education  \\\n",
       "0    12496        Married  Female   40000.0         1        Bachelors   \n",
       "1    24107        Married    Male   30000.0         3  Partial College   \n",
       "2    14177        Married    Male   80000.0         5  Partial College   \n",
       "3    24381         Single    Male   70000.0         0        Bachelors   \n",
       "4    25597         Single    Male   30000.0         0        Bachelors   \n",
       "..     ...            ...     ...       ...       ...              ...   \n",
       "995  23731        Married    Male   60000.0         2      High School   \n",
       "996  28672         Single    Male       NaN         4  Graduate Degree   \n",
       "997  11809        Married    Male   60000.0         2        Bachelors   \n",
       "998  19664         Single    Male  100000.0         3        Bachelors   \n",
       "999  12121         Single    Male   60000.0         3      High School   \n",
       "\n",
       "         Occupation Home Owner  Cars Commute Distance         Region   Age  \\\n",
       "0    Skilled Manual        Yes     0        0-1 Miles         Europe  42.0   \n",
       "1          Clerical        Yes     1        0-1 Miles         Europe  43.0   \n",
       "2      Professional         No     2        2-5 Miles         Europe  60.0   \n",
       "3      Professional        Yes     1       5-10 Miles        Pacific  41.0   \n",
       "4          Clerical         No     0        0-1 Miles         Europe  36.0   \n",
       "..              ...        ...   ...              ...            ...   ...   \n",
       "995    Professional        Yes     2        2-5 Miles  North America  54.0   \n",
       "996    Professional        Yes     0        2-5 Miles  North America  35.0   \n",
       "997  Skilled Manual        Yes     0        0-1 Miles  North America  38.0   \n",
       "998      Management         No     3        1-2 Miles  North America  38.0   \n",
       "999    Professional        Yes     2        10+ Miles  North America  53.0   \n",
       "\n",
       "                                       Purchased Bike   \n",
       "0            No                                         \n",
       "1          No                                           \n",
       "2             No                                        \n",
       "3         Yes                                           \n",
       "4    Yes                                           ...  \n",
       "..                                                 ...  \n",
       "995                                                     \n",
       "996                                                     \n",
       "997                                                     \n",
       "998                                                     \n",
       "999                                                     \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.info()\n",
    "bikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the contents of the file, columns and the datatype of the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 13 columns):\n",
      "ID                  1000 non-null int64\n",
      "Marital Status      1000 non-null object\n",
      "Gender              1000 non-null object\n",
      "Income              932 non-null float64\n",
      "Children            1000 non-null int64\n",
      "Education           1000 non-null object\n",
      "Occupation          1000 non-null object\n",
      "Home Owner          1000 non-null object\n",
      "Cars                1000 non-null int64\n",
      "Commute Distance    1000 non-null object\n",
      "Region              995 non-null object\n",
      "Age                 989 non-null float64\n",
      "Purchased Bike      1000 non-null object\n",
      "dtypes: float64(2), int64(3), object(8)\n",
      "memory usage: 101.7+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Marital Status', 'Gender', 'Income', 'Children', 'Education',\n",
       "       'Occupation', 'Home Owner', 'Cars', 'Commute Distance', 'Region', 'Age',\n",
       "       'Purchased Bike '],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.info()\n",
    "bikes\n",
    "bikes.keys()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Info shows us that many of the fields are Objects and that we've got missing values. Here we also encounter our first pitfall : bikes gives us the entire contents and we can see \"empty\" fields in the column Purchased Bikes. .Info() however , tells us that 1000/1000 of the fields are filled with values. These emtpy field therefore aren't empty.\n",
    "Keys gives us the Second pitfall : the column Purchased Bike has an extra space in the name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datacleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll start with the cleaning of our data, we'll do this column by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ID\n",
    "Is there anything in ID we can work with? Sort should give us a first indication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Purchased Bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>306</td>\n",
       "      <td>11000</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>40.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>11047</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>56.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>441</td>\n",
       "      <td>11061</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>52.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>924</td>\n",
       "      <td>11090</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>48.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>411</td>\n",
       "      <td>11116</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>43.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>29337</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>68.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>29355</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>37.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>29380</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>337</td>\n",
       "      <td>29424</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Partial High School</td>\n",
       "      <td>Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>32.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>435</td>\n",
       "      <td>29447</td>\n",
       "      <td>Single</td>\n",
       "      <td>Female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>68.0</td>\n",
       "      <td>No                                            ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Marital Status  Gender   Income  Children            Education  \\\n",
       "306  11000        Married    Male  90000.0         2            Bachelors   \n",
       "186  11047        Married  Female  30000.0         3          High School   \n",
       "441  11061        Married    Male  80000.0         2      Partial College   \n",
       "924  11090         Single    Male  90000.0         2      Partial College   \n",
       "411  11116        Married    Male  70000.0         5      Partial College   \n",
       "..     ...            ...     ...      ...       ...                  ...   \n",
       "65   29337         Single    Male  30000.0         2      Partial College   \n",
       "66   29355        Married  Female  40000.0         0      Graduate Degree   \n",
       "44   29380        Married  Female  20000.0         3          High School   \n",
       "337  29424        Married    Male  10000.0         0  Partial High School   \n",
       "435  29447         Single  Female      NaN         2            Bachelors   \n",
       "\n",
       "         Occupation Home Owner  Cars Commute Distance         Region   Age  \\\n",
       "306    Professional        Yes     0        1-2 Miles        Pacific  40.0   \n",
       "186  Skilled Manual         No     2        1-2 Miles        Pacific  56.0   \n",
       "441  Skilled Manual        Yes     2       5-10 Miles        Pacific  52.0   \n",
       "924    Professional        Yes     1        2-5 Miles  North America  48.0   \n",
       "411  Skilled Manual        Yes     2       5-10 Miles        Pacific  43.0   \n",
       "..              ...        ...   ...              ...            ...   ...   \n",
       "65         Clerical        Yes     2       5-10 Miles        Pacific  68.0   \n",
       "66         Clerical        Yes     0        0-1 Miles         Europe  37.0   \n",
       "44           Manual        Yes     0        0-1 Miles         Europe  41.0   \n",
       "337          Manual        Yes     2        0-1 Miles         Europe  32.0   \n",
       "435        Clerical         No     1        2-5 Miles         Europe  68.0   \n",
       "\n",
       "                                       Purchased Bike   \n",
       "306       Yes                                           \n",
       "186            Yes                                      \n",
       "441                Yes                                  \n",
       "924                                                     \n",
       "411                No                                   \n",
       "..                                                 ...  \n",
       "65          No                                          \n",
       "66           Yes                                        \n",
       "44     Yes                                              \n",
       "337          No                                         \n",
       "435  No                                            ...  \n",
       "\n",
       "[1000 rows x 13 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.sort_values(by=['ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ID values don't start with 1 and aren't all used. How about uniqueness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  1000\n",
       "Marital Status         2\n",
       "Gender                 2\n",
       "Income                16\n",
       "Children               6\n",
       "Education              5\n",
       "Occupation             5\n",
       "Home Owner             2\n",
       "Cars                   5\n",
       "Commute Distance       5\n",
       "Region                 3\n",
       "Age                   53\n",
       "Purchased Bike        79\n",
       "dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all of the IDs are unique and so might be of low value to us , atleast for our training purposes. We can mark this as \"Might be dropped\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marital Status + Gender\n",
    "nunique gave us only 2 Marital Statusses and Genders , we can directly recode this with the labelencoder in sklearn.preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12496</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24107</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14177</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24381</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25597</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Yes                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>23731</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>54.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>28672</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>11809</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>19664</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Management</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>12121</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>10+ Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>53.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Marital Status  Gender    Income  Children        Education  \\\n",
       "0    12496        Married  Female   40000.0         1        Bachelors   \n",
       "1    24107        Married    Male   30000.0         3  Partial College   \n",
       "2    14177        Married    Male   80000.0         5  Partial College   \n",
       "3    24381         Single    Male   70000.0         0        Bachelors   \n",
       "4    25597         Single    Male   30000.0         0        Bachelors   \n",
       "..     ...            ...     ...       ...       ...              ...   \n",
       "995  23731        Married    Male   60000.0         2      High School   \n",
       "996  28672         Single    Male       NaN         4  Graduate Degree   \n",
       "997  11809        Married    Male   60000.0         2        Bachelors   \n",
       "998  19664         Single    Male  100000.0         3        Bachelors   \n",
       "999  12121         Single    Male   60000.0         3      High School   \n",
       "\n",
       "         Occupation Home Owner  Cars Commute Distance         Region   Age  \\\n",
       "0    Skilled Manual        Yes     0        0-1 Miles         Europe  42.0   \n",
       "1          Clerical        Yes     1        0-1 Miles         Europe  43.0   \n",
       "2      Professional         No     2        2-5 Miles         Europe  60.0   \n",
       "3      Professional        Yes     1       5-10 Miles        Pacific  41.0   \n",
       "4          Clerical         No     0        0-1 Miles         Europe  36.0   \n",
       "..              ...        ...   ...              ...            ...   ...   \n",
       "995    Professional        Yes     2        2-5 Miles  North America  54.0   \n",
       "996    Professional        Yes     0        2-5 Miles  North America  35.0   \n",
       "997  Skilled Manual        Yes     0        0-1 Miles  North America  38.0   \n",
       "998      Management         No     3        1-2 Miles  North America  38.0   \n",
       "999    Professional        Yes     2        10+ Miles  North America  53.0   \n",
       "\n",
       "                                       Purchased Bike   Marital_Status_RC  \\\n",
       "0            No                                                         0   \n",
       "1          No                                                           0   \n",
       "2             No                                                        0   \n",
       "3         Yes                                                           1   \n",
       "4    Yes                                           ...                  1   \n",
       "..                                                 ...                ...   \n",
       "995                                                                     0   \n",
       "996                                                                     1   \n",
       "997                                                                     0   \n",
       "998                                                                     1   \n",
       "999                                                                     1   \n",
       "\n",
       "     Gender_RC  \n",
       "0            0  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          1  \n",
       "996          1  \n",
       "997          1  \n",
       "998          1  \n",
       "999          1  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "bikes['Marital_Status_RC'] = le.fit_transform(bikes['Marital Status'])\n",
    "bikes['Gender_RC'] = le.fit_transform(bikes['Gender'])\n",
    "bikes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now see that in Martital Status, Married has been recoded to 0 , as is Female in Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Income\n",
    "Income is the first column that has missing values, but we'll return to those after the cleaning part\n",
    "First lets see the unique entries to see if we need to clean anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 40000.,  30000.,  80000.,  70000.,  10000., 160000.,  20000.,\n",
       "        90000., 170000.,  60000.,     nan, 100000., 130000., 120000.,\n",
       "        50000., 110000., 150000.])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Income.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that every value is marked as a float but can as easily be marked as an Int.\n",
    "\n",
    "Some digging showed me the reason for the float; NaN is a type of float and I'm not allowed to recast it without first replacing the NaNs (bikes['Income_int'] =bikes['Income'].astype('int64'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Children\n",
    "lets see if Children has any weird values or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 5, 0, 2, 4])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Children.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems to be in order , no action needed for now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Education\n",
    "lets see if Education has any weird values or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bachelors', 'Partial College', 'High School',\n",
       "       'Partial High School', 'Graduate Degree'], dtype=object)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Education.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems to be in order , but we can't use these values. Time to re-encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Education_RC'] = le.fit_transform(bikes['Education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a lot of unique values , we're starting to lose oversight in the used codes for the catogories , time to switch to a more manual approach for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Marital Status</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Education</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Home Owner</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Commute Distance</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>12496</td>\n",
       "      <td>Married</td>\n",
       "      <td>Female</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>42.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>24107</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14177</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>Partial College</td>\n",
       "      <td>Professional</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>60.0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>24381</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>5-10 Miles</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>41.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>25597</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Clerical</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36.0</td>\n",
       "      <td>Yes                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>23731</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>54.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>28672</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>2-5 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>35.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>11809</td>\n",
       "      <td>Married</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Skilled Manual</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>19664</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Management</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>1-2 Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>38.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>12121</td>\n",
       "      <td>Single</td>\n",
       "      <td>Male</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "      <td>10+ Miles</td>\n",
       "      <td>North America</td>\n",
       "      <td>53.0</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID Marital Status  Gender    Income  Children        Education  \\\n",
       "0    12496        Married  Female   40000.0         1        Bachelors   \n",
       "1    24107        Married    Male   30000.0         3  Partial College   \n",
       "2    14177        Married    Male   80000.0         5  Partial College   \n",
       "3    24381         Single    Male   70000.0         0        Bachelors   \n",
       "4    25597         Single    Male   30000.0         0        Bachelors   \n",
       "..     ...            ...     ...       ...       ...              ...   \n",
       "995  23731        Married    Male   60000.0         2      High School   \n",
       "996  28672         Single    Male       NaN         4  Graduate Degree   \n",
       "997  11809        Married    Male   60000.0         2        Bachelors   \n",
       "998  19664         Single    Male  100000.0         3        Bachelors   \n",
       "999  12121         Single    Male   60000.0         3      High School   \n",
       "\n",
       "         Occupation Home Owner  Cars Commute Distance         Region   Age  \\\n",
       "0    Skilled Manual        Yes     0        0-1 Miles         Europe  42.0   \n",
       "1          Clerical        Yes     1        0-1 Miles         Europe  43.0   \n",
       "2      Professional         No     2        2-5 Miles         Europe  60.0   \n",
       "3      Professional        Yes     1       5-10 Miles        Pacific  41.0   \n",
       "4          Clerical         No     0        0-1 Miles         Europe  36.0   \n",
       "..              ...        ...   ...              ...            ...   ...   \n",
       "995    Professional        Yes     2        2-5 Miles  North America  54.0   \n",
       "996    Professional        Yes     0        2-5 Miles  North America  35.0   \n",
       "997  Skilled Manual        Yes     0        0-1 Miles  North America  38.0   \n",
       "998      Management         No     3        1-2 Miles  North America  38.0   \n",
       "999    Professional        Yes     2        10+ Miles  North America  53.0   \n",
       "\n",
       "                                       Purchased Bike   Marital_Status_RC  \\\n",
       "0            No                                                         0   \n",
       "1          No                                                           0   \n",
       "2             No                                                        0   \n",
       "3         Yes                                                           1   \n",
       "4    Yes                                           ...                  1   \n",
       "..                                                 ...                ...   \n",
       "995                                                                     0   \n",
       "996                                                                     1   \n",
       "997                                                                     0   \n",
       "998                                                                     1   \n",
       "999                                                                     1   \n",
       "\n",
       "     Gender_RC  \n",
       "0            0  \n",
       "1            1  \n",
       "2            1  \n",
       "3            1  \n",
       "4            1  \n",
       "..         ...  \n",
       "995          1  \n",
       "996          1  \n",
       "997          1  \n",
       "998          1  \n",
       "999          1  \n",
       "\n",
       "[1000 rows x 15 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First let's drop the recoded Education\n",
    "bikes.drop(columns=['Education_RC'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recreate manually\n",
    "bikes['Education_RC'] = bikes['Education'].map( {'Bachelors': 0, 'Partial College': 1, 'High School': 2, 'Partial High School': 3, 'Graduate Degree': 4} ).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Occupation\n",
    "lets see if Occupation has any weird values or missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Skilled Manual', 'Clerical', 'Professional', 'Manual',\n",
       "       'Management'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Occupation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "everything seems to be in order , but we can't use these values. Time to re-encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Occupation_RC'] = bikes['Occupation'].map( {'Skilled Manual': 0, 'Clerical': 1, 'Professional': 2, 'Manual': 3, 'Management': 4} ).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Home Owner\n",
    "We've already seen that Home Owner only has 2 values ; yes and no.We can't use these values so time to re-encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Home_Owner_RC'] = bikes['Home Owner'].map( {'No': 0, 'Yes': 1} ).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cars\n",
    "Cars already is an int and has 1000 values but let's check the uniques to be sure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 3])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Cars.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everyhing seems to be in order and because it's an int already , no need to reencode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Commute Distance\n",
    "is an object filled with 1000 values but it's a mix between letters and numbers.\n",
    "let's see the uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['0-1 Miles', '2-5 Miles', '5-10 Miles', '1-2 Miles', '10+ Miles'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['Commute Distance'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uniques are clear but we'll need to reform the values. we'll removes all the miles and use the max distance instead of the spread. Using 11 for 10+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First remove all the non-digits\n",
    "bikes['Commute_Distance_RC'] = bikes['Commute Distance'].str.replace(r'\\D', '').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recode\n",
    "bikes['Commute_Distance_RC'] = bikes['Commute_Distance_RC'].map( {1:1, 25: 5,10: 11, 510: 10, 12: 2}  )\n",
    "#1 still has to be mapped, otherwise it seems to be replaced with NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Region\n",
    "Region has 5 missing values to start with , lets see the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Europe', 'Pacific', nan, 'North America'], dtype=object)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.Region.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll need to recode. to make them usefull but first we'll need to replace the NaN and remember to \"fix\" it later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age \n",
    "Income is the third column that has missing values, but we'll return to those after the cleaning part. First lets see the unique entries to see if we need to clean anything"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No cleaning needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purchased Bike\n",
    "The first small fix is fixing the title and removing the extra space : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Purchased Bike'] = bikes['Purchased Bike ']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that the 1000 values were filled in but we're also told that our extra set in contained within. lets see the uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No                                       ',\n",
       "       'No                                         ',\n",
       "       'No                                      ',\n",
       "       'Yes                                         ',\n",
       "       'Yes                                                ',\n",
       "       'Yes                                        ',\n",
       "       'No                                   ',\n",
       "       'Yes                                          ',\n",
       "       'Yes                                    ',\n",
       "       'No                                          ',\n",
       "       'No                                    ',\n",
       "       'Yes                                   ',\n",
       "       'Yes                                             ',\n",
       "       'No                                             ',\n",
       "       'Yes                                      ',\n",
       "       'Yes                                              ',\n",
       "       'No                                              ',\n",
       "       'No                                                ',\n",
       "       'No                                        ',\n",
       "       'No                                 ',\n",
       "       'Yes                                            ',\n",
       "       'No                                                 ',\n",
       "       'Yes                                     ',\n",
       "       'Yes                                 ',\n",
       "       'Yes                              ',\n",
       "       'No                                            ',\n",
       "       'Yes                                                    ',\n",
       "       'No                                                    ',\n",
       "       'No                                                   ',\n",
       "       'Yes                                           ',\n",
       "       'No                                           ',\n",
       "       'Yes                                               ',\n",
       "       'No                                     ',\n",
       "       'No                                  ',\n",
       "       'Yes                                                 ',\n",
       "       'No                                               ',\n",
       "       'No                                                     ',\n",
       "       'Yes                                ',\n",
       "       'Yes                                       ',\n",
       "       'Yes                               ',\n",
       "       'No                                                  ',\n",
       "       'Yes                                  ',\n",
       "       'No                                ',\n",
       "       'No                               ',\n",
       "       'No                             ',\n",
       "       'Yes                             ',\n",
       "       'Yes                                                      ',\n",
       "       'No                       ', 'No                              ',\n",
       "       'Yes                            ',\n",
       "       'Yes                           ', 'No                          ',\n",
       "       'No                           ', 'Yes                         ',\n",
       "       'Yes                          ', 'No                            ',\n",
       "       'No                        ', 'Yes                       ',\n",
       "       'Yes                      ', 'No                         ',\n",
       "       'No                      ', '                                   ',\n",
       "       '                                 ',\n",
       "       '                                ',\n",
       "       '                               ',\n",
       "       '                                       ',\n",
       "       '                                  ',\n",
       "       '                              ', '                             ',\n",
       "       '                                         ',\n",
       "       '                                     ',\n",
       "       '                                    ',\n",
       "       '                                      ',\n",
       "       '                          ', '                           ',\n",
       "       '                            ',\n",
       "       '                                          ',\n",
       "       '                                        ',\n",
       "       '                                           '], dtype=object)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['Purchased Bike'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of extra empty spaces, let's remove these first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "bikes['Purchased Bike' ]= bikes['Purchased Bike'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', ''], dtype=object)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['Purchased Bike'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we know that the left over empty spaces are the testset that we have to split off but the spaces aren't truelly empty. lets replace those white spaces with NaN values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "bikes = bikes.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', nan], dtype=object)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes['Purchased Bike'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      "Income                 932 non-null float64\n",
      "Children               1000 non-null int64\n",
      "Cars                   1000 non-null int64\n",
      "Region                 995 non-null object\n",
      "Age                    989 non-null float64\n",
      "Marital_Status_RC      1000 non-null int64\n",
      "Gender_RC              1000 non-null int64\n",
      "Education_RC           1000 non-null int64\n",
      "Occupation_RC          1000 non-null int64\n",
      "Home_Owner_RC          1000 non-null int64\n",
      "Commute_Distance_RC    1000 non-null int64\n",
      "Purchased Bike         808 non-null object\n",
      "dtypes: float64(2), int64(8), object(2)\n",
      "memory usage: 93.9+ KB\n"
     ]
    }
   ],
   "source": [
    "complete_RC = bikes.drop(['ID','Marital Status','Gender','Education','Occupation','Home Owner','Commute Distance','Purchased Bike ' ], axis =1)\n",
    "complete_RC.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_RC_isnull = complete_RC[complete_RC['Purchased Bike'].isnull()]\n",
    "complete_RC_notnull = complete_RC[complete_RC['Purchased Bike'].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that Income , Region and Age have missing values. Let's see if we can fill these"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split the null and not null values \n",
    "- recode Region\n",
    "- recode used variables (Income,Age,Education,Occupation and Gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "803 5\n"
     ]
    }
   ],
   "source": [
    "set_region_notnull = complete_RC_notnull[complete_RC_notnull['Region'].notnull()]\n",
    "set_region_null = complete_RC_notnull[complete_RC_notnull['Region'].isnull()]\n",
    "print(len(set_region_notnull),len(set_region_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "588 147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mike/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/mike/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "set_region_null = set_region_null[set_region_null['Income'].notnull()]\n",
    "set_region_notnull = set_region_notnull[set_region_notnull['Income'].notnull()]\n",
    "set_region_null = set_region_null[set_region_null['Age'].notnull()]\n",
    "set_region_notnull = set_region_notnull[set_region_notnull['Age'].notnull()]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainingSet, testSet = train_test_split(set_region_notnull, test_size=0.2)\n",
    "print(len(trainingSet),len(testSet))\n",
    "trainingSet['Region_RC'] = le.fit_transform(trainingSet['Region'])\n",
    "testSet['Region_RC'] = le.fit_transform(testSet['Region'])\n",
    "set_region_null['Region_RC'] = le.fit_transform(set_region_null['Region'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(zip(trainingSet['Income'],trainingSet['Age'],trainingSet['Occupation_RC'],trainingSet['Education_RC'],trainingSet['Gender_RC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>657</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>747</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>359</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>355</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>294</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Europe</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>626</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>North America</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>244</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Europe</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>588 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars         Region   Age  Marital_Status_RC  \\\n",
       "657   70000.0         1     1  North America  44.0                  0   \n",
       "154   80000.0         5     3        Pacific  40.0                  1   \n",
       "500   60000.0         5     1  North America  47.0                  0   \n",
       "747   70000.0         1     1  North America  44.0                  1   \n",
       "359   80000.0         0     3        Pacific  30.0                  0   \n",
       "..        ...       ...   ...            ...   ...                ...   \n",
       "355   80000.0         0     3        Pacific  32.0                  1   \n",
       "294   20000.0         0     1         Europe  36.0                  1   \n",
       "626   60000.0         0     2  North America  29.0                  0   \n",
       "84    40000.0         2     1        Pacific  52.0                  1   \n",
       "244  120000.0         3     2         Europe  52.0                  0   \n",
       "\n",
       "     Gender_RC  Education_RC  Occupation_RC  Home_Owner_RC  \\\n",
       "657          1             1              0              1   \n",
       "154          1             4              4              1   \n",
       "500          1             0              2              1   \n",
       "747          0             0              2              0   \n",
       "359          1             0              2              1   \n",
       "..         ...           ...            ...            ...   \n",
       "355          1             0              2              1   \n",
       "294          1             1              3              0   \n",
       "626          0             1              0              1   \n",
       "84           1             0              4              0   \n",
       "244          0             0              4              0   \n",
       "\n",
       "     Commute_Distance_RC Purchased Bike  Region_RC  \n",
       "657                    1             No          1  \n",
       "154                    1             No          2  \n",
       "500                    5             No          1  \n",
       "747                    1             No          1  \n",
       "359                   11             No          2  \n",
       "..                   ...            ...        ...  \n",
       "355                   11             No          2  \n",
       "294                    5            Yes          0  \n",
       "626                   10             No          1  \n",
       "84                    10            Yes          2  \n",
       "244                   11            Yes          0  \n",
       "\n",
       "[588 rows x 13 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1 0.8707482993197279\n",
      "Accuracy: 2 0.8435374149659864\n",
      "Accuracy: 3 0.8639455782312925\n",
      "Accuracy: 4 0.7891156462585034\n",
      "Accuracy: 5 0.7755102040816326\n",
      "Accuracy: 6 0.7755102040816326\n",
      "Accuracy: 7 0.8163265306122449\n",
      "Accuracy: 8 0.7959183673469388\n",
      "Accuracy: 9 0.7755102040816326\n",
      "Accuracy: 10 0.7210884353741497\n",
      "Accuracy: 11 0.7482993197278912\n",
      "Accuracy: 12 0.7551020408163265\n",
      "Accuracy: 13 0.7482993197278912\n",
      "Accuracy: 14 0.7414965986394558\n",
      "Accuracy: 15 0.6870748299319728\n",
      "Accuracy: 16 0.7074829931972789\n",
      "Accuracy: 17 0.6802721088435374\n",
      "Accuracy: 18 0.6938775510204082\n",
      "Accuracy: 19 0.673469387755102\n",
      "Accuracy: 20 0.673469387755102\n",
      "Accuracy: 21 0.6530612244897959\n",
      "Accuracy: 22 0.6462585034013606\n",
      "Accuracy: 23 0.6462585034013606\n",
      "Accuracy: 24 0.6326530612244898\n",
      "Accuracy: 25 0.673469387755102\n",
      "Accuracy: 26 0.6802721088435374\n",
      "Accuracy: 27 0.6938775510204082\n",
      "Accuracy: 28 0.7006802721088435\n",
      "Accuracy: 29 0.673469387755102\n",
      "Accuracy: 30 0.6802721088435374\n",
      "Accuracy: 31 0.673469387755102\n",
      "Accuracy: 32 0.6666666666666666\n",
      "Accuracy: 33 0.6462585034013606\n",
      "Accuracy: 34 0.6666666666666666\n",
      "Accuracy: 35 0.6258503401360545\n",
      "Accuracy: 36 0.6326530612244898\n",
      "Accuracy: 37 0.6258503401360545\n",
      "Accuracy: 38 0.6530612244897959\n",
      "Accuracy: 39 0.6394557823129252\n",
      "Accuracy: 40 0.6530612244897959\n",
      "Accuracy: 41 0.6394557823129252\n",
      "Accuracy: 42 0.6598639455782312\n",
      "Accuracy: 43 0.6530612244897959\n",
      "Accuracy: 44 0.6666666666666666\n",
      "Accuracy: 45 0.6666666666666666\n",
      "Accuracy: 46 0.6666666666666666\n",
      "Accuracy: 47 0.673469387755102\n",
      "Accuracy: 48 0.6802721088435374\n",
      "Accuracy: 49 0.673469387755102\n",
      "Accuracy: 50 0.673469387755102\n",
      "Accuracy: 51 0.6530612244897959\n",
      "Accuracy: 52 0.6394557823129252\n",
      "Accuracy: 53 0.6326530612244898\n",
      "Accuracy: 54 0.6190476190476191\n",
      "Accuracy: 55 0.6190476190476191\n",
      "Accuracy: 56 0.6258503401360545\n",
      "Accuracy: 57 0.6258503401360545\n",
      "Accuracy: 58 0.6258503401360545\n",
      "Accuracy: 59 0.6394557823129252\n",
      "Accuracy: 60 0.6326530612244898\n",
      "Accuracy: 61 0.6462585034013606\n",
      "Accuracy: 62 0.6326530612244898\n",
      "Accuracy: 63 0.6326530612244898\n",
      "Accuracy: 64 0.6326530612244898\n",
      "Accuracy: 65 0.6326530612244898\n",
      "Accuracy: 66 0.6394557823129252\n",
      "Accuracy: 67 0.6326530612244898\n",
      "Accuracy: 68 0.6462585034013606\n",
      "Accuracy: 69 0.6394557823129252\n",
      "Accuracy: 70 0.6326530612244898\n",
      "Accuracy: 71 0.6326530612244898\n",
      "Accuracy: 72 0.6326530612244898\n",
      "Accuracy: 73 0.6394557823129252\n",
      "Accuracy: 74 0.6394557823129252\n",
      "Accuracy: 75 0.5986394557823129\n",
      "Accuracy: 76 0.5850340136054422\n",
      "Accuracy: 77 0.5850340136054422\n",
      "Accuracy: 78 0.5782312925170068\n",
      "Accuracy: 79 0.5782312925170068\n",
      "Accuracy: 80 0.5714285714285714\n",
      "Accuracy: 81 0.5850340136054422\n",
      "Accuracy: 82 0.5850340136054422\n",
      "Accuracy: 83 0.5986394557823129\n",
      "Accuracy: 84 0.5918367346938775\n",
      "Accuracy: 85 0.5986394557823129\n",
      "Accuracy: 86 0.6190476190476191\n",
      "Accuracy: 87 0.6190476190476191\n",
      "Accuracy: 88 0.6190476190476191\n",
      "Accuracy: 89 0.6258503401360545\n",
      "Accuracy: 90 0.6122448979591837\n",
      "Accuracy: 91 0.6190476190476191\n",
      "Accuracy: 92 0.6122448979591837\n",
      "Accuracy: 93 0.6122448979591837\n",
      "Accuracy: 94 0.6326530612244898\n",
      "Accuracy: 95 0.6258503401360545\n",
      "Accuracy: 96 0.6394557823129252\n",
      "Accuracy: 97 0.6258503401360545\n",
      "Accuracy: 98 0.6666666666666666\n",
      "Accuracy: 99 0.6666666666666666\n",
      "Accuracy: 100 0.6802721088435374\n",
      "Accuracy: 101 0.6802721088435374\n",
      "Accuracy: 102 0.6870748299319728\n",
      "Accuracy: 103 0.6870748299319728\n",
      "Accuracy: 104 0.6870748299319728\n",
      "Accuracy: 105 0.6870748299319728\n",
      "Accuracy: 106 0.673469387755102\n",
      "Accuracy: 107 0.6870748299319728\n",
      "Accuracy: 108 0.6870748299319728\n",
      "Accuracy: 109 0.6870748299319728\n",
      "Accuracy: 110 0.6938775510204082\n",
      "Accuracy: 111 0.6938775510204082\n",
      "Accuracy: 112 0.6938775510204082\n",
      "Accuracy: 113 0.6802721088435374\n",
      "Accuracy: 114 0.6802721088435374\n",
      "Accuracy: 115 0.6802721088435374\n",
      "Accuracy: 116 0.673469387755102\n",
      "Accuracy: 117 0.673469387755102\n",
      "Accuracy: 118 0.673469387755102\n",
      "Accuracy: 119 0.6802721088435374\n",
      "Accuracy: 120 0.6598639455782312\n",
      "Accuracy: 121 0.6870748299319728\n",
      "Accuracy: 122 0.6666666666666666\n",
      "Accuracy: 123 0.6598639455782312\n",
      "Accuracy: 124 0.6326530612244898\n",
      "Accuracy: 125 0.6326530612244898\n",
      "Accuracy: 126 0.6462585034013606\n",
      "Accuracy: 127 0.6462585034013606\n",
      "Accuracy: 128 0.6394557823129252\n",
      "Accuracy: 129 0.6394557823129252\n",
      "Accuracy: 130 0.6394557823129252\n",
      "Accuracy: 131 0.6462585034013606\n",
      "Accuracy: 132 0.6394557823129252\n",
      "Accuracy: 133 0.6394557823129252\n",
      "Accuracy: 134 0.6530612244897959\n",
      "Accuracy: 135 0.6462585034013606\n",
      "Accuracy: 136 0.6462585034013606\n",
      "Accuracy: 137 0.6394557823129252\n",
      "Accuracy: 138 0.6326530612244898\n",
      "Accuracy: 139 0.6326530612244898\n",
      "Accuracy: 140 0.6326530612244898\n",
      "Accuracy: 141 0.6326530612244898\n",
      "Accuracy: 142 0.6326530612244898\n",
      "Accuracy: 143 0.6326530612244898\n",
      "Accuracy: 144 0.6394557823129252\n",
      "Accuracy: 145 0.6326530612244898\n",
      "Accuracy: 146 0.6326530612244898\n",
      "Accuracy: 147 0.6326530612244898\n",
      "Accuracy: 148 0.6394557823129252\n",
      "Accuracy: 149 0.6394557823129252\n",
      "Accuracy: 150 0.6394557823129252\n",
      "Accuracy: 151 0.6326530612244898\n",
      "Accuracy: 152 0.6394557823129252\n",
      "Accuracy: 153 0.6394557823129252\n",
      "Accuracy: 154 0.6258503401360545\n",
      "Accuracy: 155 0.6258503401360545\n",
      "Accuracy: 156 0.6190476190476191\n",
      "Accuracy: 157 0.6326530612244898\n",
      "Accuracy: 158 0.6122448979591837\n",
      "Accuracy: 159 0.6326530612244898\n",
      "Accuracy: 160 0.6258503401360545\n",
      "Accuracy: 161 0.6326530612244898\n",
      "Accuracy: 162 0.6122448979591837\n",
      "Accuracy: 163 0.6326530612244898\n",
      "Accuracy: 164 0.6258503401360545\n",
      "Accuracy: 165 0.6326530612244898\n",
      "Accuracy: 166 0.6122448979591837\n",
      "Accuracy: 167 0.6190476190476191\n",
      "Accuracy: 168 0.6190476190476191\n",
      "Accuracy: 169 0.6394557823129252\n",
      "Accuracy: 170 0.6462585034013606\n",
      "Accuracy: 171 0.6462585034013606\n",
      "Accuracy: 172 0.6462585034013606\n",
      "Accuracy: 173 0.6394557823129252\n",
      "Accuracy: 174 0.6394557823129252\n",
      "Accuracy: 175 0.6394557823129252\n",
      "Accuracy: 176 0.6394557823129252\n",
      "Accuracy: 177 0.6394557823129252\n",
      "Accuracy: 178 0.6394557823129252\n",
      "Accuracy: 179 0.6394557823129252\n",
      "Accuracy: 180 0.6394557823129252\n",
      "Accuracy: 181 0.6394557823129252\n",
      "Accuracy: 182 0.6394557823129252\n",
      "Accuracy: 183 0.6394557823129252\n",
      "Accuracy: 184 0.6394557823129252\n",
      "Accuracy: 185 0.6394557823129252\n",
      "Accuracy: 186 0.6394557823129252\n",
      "Accuracy: 187 0.6394557823129252\n",
      "Accuracy: 188 0.6394557823129252\n",
      "Accuracy: 189 0.6394557823129252\n",
      "Accuracy: 190 0.6394557823129252\n",
      "Accuracy: 191 0.6394557823129252\n",
      "Accuracy: 192 0.6394557823129252\n",
      "Accuracy: 193 0.6394557823129252\n",
      "Accuracy: 194 0.6394557823129252\n",
      "Accuracy: 195 0.6394557823129252\n",
      "Accuracy: 196 0.6394557823129252\n",
      "Accuracy: 197 0.6394557823129252\n",
      "Accuracy: 198 0.6394557823129252\n",
      "Accuracy: 199 0.6394557823129252\n",
      "Accuracy: 200 0.6394557823129252\n",
      "Accuracy: 201 0.6394557823129252\n",
      "Accuracy: 202 0.6394557823129252\n",
      "Accuracy: 203 0.6394557823129252\n",
      "Accuracy: 204 0.6394557823129252\n",
      "Accuracy: 205 0.6394557823129252\n",
      "Accuracy: 206 0.6394557823129252\n",
      "Accuracy: 207 0.6394557823129252\n",
      "Accuracy: 208 0.6394557823129252\n",
      "Accuracy: 209 0.6394557823129252\n",
      "Accuracy: 210 0.6394557823129252\n",
      "Accuracy: 211 0.6394557823129252\n",
      "Accuracy: 212 0.6394557823129252\n",
      "Accuracy: 213 0.6394557823129252\n",
      "Accuracy: 214 0.6394557823129252\n",
      "Accuracy: 215 0.6394557823129252\n",
      "Accuracy: 216 0.6394557823129252\n",
      "Accuracy: 217 0.6394557823129252\n",
      "Accuracy: 218 0.6394557823129252\n",
      "Accuracy: 219 0.6394557823129252\n",
      "Accuracy: 220 0.6394557823129252\n",
      "Accuracy: 221 0.6394557823129252\n",
      "Accuracy: 222 0.6394557823129252\n",
      "Accuracy: 223 0.6394557823129252\n",
      "Accuracy: 224 0.6394557823129252\n",
      "Accuracy: 225 0.6394557823129252\n",
      "Accuracy: 226 0.6394557823129252\n",
      "Accuracy: 227 0.6394557823129252\n",
      "Accuracy: 228 0.6394557823129252\n",
      "Accuracy: 229 0.6394557823129252\n",
      "Accuracy: 230 0.6394557823129252\n",
      "Accuracy: 231 0.6394557823129252\n",
      "Accuracy: 232 0.6394557823129252\n",
      "Accuracy: 233 0.6394557823129252\n",
      "Accuracy: 234 0.6394557823129252\n",
      "Accuracy: 235 0.6394557823129252\n",
      "Accuracy: 236 0.6394557823129252\n",
      "Accuracy: 237 0.6394557823129252\n",
      "Accuracy: 238 0.6394557823129252\n",
      "Accuracy: 239 0.6394557823129252\n",
      "Accuracy: 240 0.6394557823129252\n",
      "Accuracy: 241 0.6394557823129252\n",
      "Accuracy: 242 0.6326530612244898\n",
      "Accuracy: 243 0.6530612244897959\n",
      "Accuracy: 244 0.6394557823129252\n",
      "Accuracy: 245 0.6530612244897959\n",
      "Accuracy: 246 0.6530612244897959\n",
      "Accuracy: 247 0.6530612244897959\n",
      "Accuracy: 248 0.6530612244897959\n",
      "Accuracy: 249 0.6530612244897959\n",
      "Accuracy: 250 0.6530612244897959\n",
      "Accuracy: 251 0.6530612244897959\n",
      "Accuracy: 252 0.6530612244897959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 253 0.6530612244897959\n",
      "Accuracy: 254 0.6530612244897959\n",
      "Accuracy: 255 0.6530612244897959\n",
      "Accuracy: 256 0.6530612244897959\n",
      "Accuracy: 257 0.6326530612244898\n",
      "Accuracy: 258 0.6326530612244898\n",
      "Accuracy: 259 0.6326530612244898\n",
      "Accuracy: 260 0.6326530612244898\n",
      "Accuracy: 261 0.6326530612244898\n",
      "Accuracy: 262 0.6326530612244898\n",
      "Accuracy: 263 0.6326530612244898\n",
      "Accuracy: 264 0.6326530612244898\n",
      "Accuracy: 265 0.6326530612244898\n",
      "Accuracy: 266 0.6326530612244898\n",
      "Accuracy: 267 0.6326530612244898\n",
      "Accuracy: 268 0.6326530612244898\n",
      "Accuracy: 269 0.6326530612244898\n",
      "Accuracy: 270 0.6326530612244898\n",
      "Accuracy: 271 0.6326530612244898\n",
      "Accuracy: 272 0.6326530612244898\n",
      "Accuracy: 273 0.6326530612244898\n",
      "Accuracy: 274 0.6326530612244898\n",
      "Accuracy: 275 0.6326530612244898\n",
      "Accuracy: 276 0.6326530612244898\n",
      "Accuracy: 277 0.6326530612244898\n",
      "Accuracy: 278 0.6326530612244898\n",
      "Accuracy: 279 0.6326530612244898\n",
      "Accuracy: 280 0.6326530612244898\n",
      "Accuracy: 281 0.6326530612244898\n",
      "Accuracy: 282 0.6326530612244898\n",
      "Accuracy: 283 0.6326530612244898\n",
      "Accuracy: 284 0.6326530612244898\n",
      "Accuracy: 285 0.6326530612244898\n",
      "Accuracy: 286 0.6326530612244898\n",
      "Accuracy: 287 0.6326530612244898\n",
      "Accuracy: 288 0.6326530612244898\n",
      "Accuracy: 289 0.6326530612244898\n",
      "Accuracy: 290 0.6326530612244898\n",
      "Accuracy: 291 0.6326530612244898\n",
      "Accuracy: 292 0.6326530612244898\n",
      "Accuracy: 293 0.6326530612244898\n",
      "Accuracy: 294 0.6326530612244898\n",
      "Accuracy: 295 0.6054421768707483\n",
      "Accuracy: 296 0.6394557823129252\n",
      "Accuracy: 297 0.6054421768707483\n",
      "Accuracy: 298 0.6054421768707483\n",
      "Accuracy: 299 0.6054421768707483\n",
      "Accuracy: 300 0.6054421768707483\n",
      "Accuracy: 301 0.6054421768707483\n",
      "Accuracy: 302 0.6054421768707483\n",
      "Accuracy: 303 0.6054421768707483\n",
      "Accuracy: 304 0.6054421768707483\n",
      "Accuracy: 305 0.6054421768707483\n",
      "Accuracy: 306 0.6054421768707483\n",
      "Accuracy: 307 0.6054421768707483\n",
      "Accuracy: 308 0.6054421768707483\n",
      "Accuracy: 309 0.6054421768707483\n",
      "Accuracy: 310 0.6054421768707483\n",
      "Accuracy: 311 0.6054421768707483\n",
      "Accuracy: 312 0.6054421768707483\n",
      "Accuracy: 313 0.6054421768707483\n",
      "Accuracy: 314 0.6054421768707483\n",
      "Accuracy: 315 0.6054421768707483\n",
      "Accuracy: 316 0.6054421768707483\n",
      "Accuracy: 317 0.6054421768707483\n",
      "Accuracy: 318 0.6054421768707483\n",
      "Accuracy: 319 0.6054421768707483\n",
      "Accuracy: 320 0.6054421768707483\n",
      "Accuracy: 321 0.6054421768707483\n",
      "Accuracy: 322 0.6054421768707483\n",
      "Accuracy: 323 0.6054421768707483\n",
      "Accuracy: 324 0.6054421768707483\n",
      "Accuracy: 325 0.6054421768707483\n",
      "Accuracy: 326 0.6054421768707483\n",
      "Accuracy: 327 0.6054421768707483\n",
      "Accuracy: 328 0.6054421768707483\n",
      "Accuracy: 329 0.6054421768707483\n",
      "Accuracy: 330 0.6054421768707483\n",
      "Accuracy: 331 0.6054421768707483\n",
      "Accuracy: 332 0.6054421768707483\n",
      "Accuracy: 333 0.6054421768707483\n",
      "Accuracy: 334 0.6054421768707483\n",
      "Accuracy: 335 0.6054421768707483\n",
      "Accuracy: 336 0.6054421768707483\n",
      "Accuracy: 337 0.6054421768707483\n",
      "Accuracy: 338 0.6054421768707483\n",
      "Accuracy: 339 0.6054421768707483\n",
      "Accuracy: 340 0.6054421768707483\n",
      "Accuracy: 341 0.6054421768707483\n",
      "Accuracy: 342 0.6054421768707483\n",
      "Accuracy: 343 0.6054421768707483\n",
      "Accuracy: 344 0.6054421768707483\n",
      "Accuracy: 345 0.6054421768707483\n",
      "Accuracy: 346 0.6054421768707483\n",
      "Accuracy: 347 0.6054421768707483\n",
      "Accuracy: 348 0.6054421768707483\n",
      "Accuracy: 349 0.6054421768707483\n",
      "Accuracy: 350 0.6054421768707483\n",
      "Accuracy: 351 0.6054421768707483\n",
      "Accuracy: 352 0.6054421768707483\n",
      "Accuracy: 353 0.6054421768707483\n",
      "Accuracy: 354 0.6054421768707483\n",
      "Accuracy: 355 0.6054421768707483\n",
      "Accuracy: 356 0.6054421768707483\n",
      "Accuracy: 357 0.6054421768707483\n",
      "Accuracy: 358 0.6054421768707483\n",
      "Accuracy: 359 0.6054421768707483\n",
      "Accuracy: 360 0.6054421768707483\n",
      "Accuracy: 361 0.6054421768707483\n",
      "Accuracy: 362 0.6054421768707483\n",
      "Accuracy: 363 0.6054421768707483\n",
      "Accuracy: 364 0.6054421768707483\n",
      "Accuracy: 365 0.6054421768707483\n",
      "Accuracy: 366 0.6054421768707483\n",
      "Accuracy: 367 0.6054421768707483\n",
      "Accuracy: 368 0.6054421768707483\n",
      "Accuracy: 369 0.6054421768707483\n",
      "Accuracy: 370 0.6054421768707483\n",
      "Accuracy: 371 0.6054421768707483\n",
      "Accuracy: 372 0.6054421768707483\n",
      "Accuracy: 373 0.6054421768707483\n",
      "Accuracy: 374 0.6054421768707483\n",
      "Accuracy: 375 0.6054421768707483\n",
      "Accuracy: 376 0.6054421768707483\n",
      "Accuracy: 377 0.6054421768707483\n",
      "Accuracy: 378 0.6054421768707483\n",
      "Accuracy: 379 0.6054421768707483\n",
      "Accuracy: 380 0.6054421768707483\n",
      "Accuracy: 381 0.6054421768707483\n",
      "Accuracy: 382 0.6054421768707483\n",
      "Accuracy: 383 0.6054421768707483\n",
      "Accuracy: 384 0.6054421768707483\n",
      "Accuracy: 385 0.6054421768707483\n",
      "Accuracy: 386 0.6054421768707483\n",
      "Accuracy: 387 0.6054421768707483\n",
      "Accuracy: 388 0.6054421768707483\n",
      "Accuracy: 389 0.6054421768707483\n",
      "Accuracy: 390 0.6054421768707483\n",
      "Accuracy: 391 0.6054421768707483\n",
      "Accuracy: 392 0.6054421768707483\n",
      "Accuracy: 393 0.6054421768707483\n",
      "Accuracy: 394 0.6054421768707483\n",
      "Accuracy: 395 0.6054421768707483\n",
      "Accuracy: 396 0.6054421768707483\n",
      "Accuracy: 397 0.6054421768707483\n",
      "Accuracy: 398 0.6054421768707483\n",
      "Accuracy: 399 0.6054421768707483\n",
      "Accuracy: 400 0.6054421768707483\n",
      "Accuracy: 401 0.6054421768707483\n",
      "Accuracy: 402 0.6054421768707483\n",
      "Accuracy: 403 0.6054421768707483\n",
      "Accuracy: 404 0.6054421768707483\n",
      "Accuracy: 405 0.6054421768707483\n",
      "Accuracy: 406 0.6054421768707483\n",
      "Accuracy: 407 0.5782312925170068\n",
      "Accuracy: 408 0.5782312925170068\n",
      "Accuracy: 409 0.5714285714285714\n",
      "Accuracy: 410 0.5714285714285714\n",
      "Accuracy: 411 0.5714285714285714\n",
      "Accuracy: 412 0.5714285714285714\n",
      "Accuracy: 413 0.5578231292517006\n",
      "Accuracy: 414 0.5578231292517006\n",
      "Accuracy: 415 0.5578231292517006\n",
      "Accuracy: 416 0.5578231292517006\n",
      "Accuracy: 417 0.5578231292517006\n",
      "Accuracy: 418 0.5578231292517006\n",
      "Accuracy: 419 0.5578231292517006\n",
      "Accuracy: 420 0.5102040816326531\n",
      "Accuracy: 421 0.5034013605442177\n",
      "Accuracy: 422 0.46258503401360546\n",
      "Accuracy: 423 0.42857142857142855\n",
      "Accuracy: 424 0.40816326530612246\n",
      "Accuracy: 425 0.3877551020408163\n",
      "Accuracy: 426 0.3877551020408163\n",
      "Accuracy: 427 0.3877551020408163\n",
      "Accuracy: 428 0.3877551020408163\n",
      "Accuracy: 429 0.3877551020408163\n",
      "Accuracy: 430 0.3877551020408163\n",
      "Accuracy: 431 0.3877551020408163\n",
      "Accuracy: 432 0.3877551020408163\n",
      "Accuracy: 433 0.3877551020408163\n",
      "Accuracy: 434 0.3877551020408163\n",
      "Accuracy: 435 0.3877551020408163\n",
      "Accuracy: 436 0.3877551020408163\n",
      "Accuracy: 437 0.3877551020408163\n",
      "Accuracy: 438 0.3877551020408163\n",
      "Accuracy: 439 0.3877551020408163\n",
      "Accuracy: 440 0.3877551020408163\n",
      "Accuracy: 441 0.3877551020408163\n",
      "Accuracy: 442 0.3877551020408163\n",
      "Accuracy: 443 0.3877551020408163\n",
      "Accuracy: 444 0.3877551020408163\n",
      "Accuracy: 445 0.3877551020408163\n",
      "Accuracy: 446 0.3877551020408163\n",
      "Accuracy: 447 0.3877551020408163\n",
      "Accuracy: 448 0.3877551020408163\n",
      "Accuracy: 449 0.3877551020408163\n",
      "Accuracy: 450 0.3877551020408163\n",
      "Accuracy: 451 0.3877551020408163\n",
      "Accuracy: 452 0.3877551020408163\n",
      "Accuracy: 453 0.3877551020408163\n",
      "Accuracy: 454 0.3877551020408163\n",
      "Accuracy: 455 0.3877551020408163\n",
      "Accuracy: 456 0.3877551020408163\n",
      "Accuracy: 457 0.3877551020408163\n",
      "Accuracy: 458 0.3877551020408163\n",
      "Accuracy: 459 0.3877551020408163\n",
      "Accuracy: 460 0.3877551020408163\n",
      "Accuracy: 461 0.3877551020408163\n",
      "Accuracy: 462 0.3877551020408163\n",
      "Accuracy: 463 0.3877551020408163\n",
      "Accuracy: 464 0.3877551020408163\n",
      "Accuracy: 465 0.3877551020408163\n",
      "Accuracy: 466 0.3877551020408163\n",
      "Accuracy: 467 0.3877551020408163\n",
      "Accuracy: 468 0.3877551020408163\n",
      "Accuracy: 469 0.3877551020408163\n",
      "Accuracy: 470 0.3877551020408163\n",
      "Accuracy: 471 0.3877551020408163\n",
      "Accuracy: 472 0.3877551020408163\n",
      "Accuracy: 473 0.3877551020408163\n",
      "Accuracy: 474 0.3877551020408163\n",
      "Accuracy: 475 0.3877551020408163\n",
      "Accuracy: 476 0.3877551020408163\n",
      "Accuracy: 477 0.3877551020408163\n",
      "Accuracy: 478 0.3877551020408163\n",
      "Accuracy: 479 0.3877551020408163\n",
      "Accuracy: 480 0.3877551020408163\n",
      "Accuracy: 481 0.3877551020408163\n",
      "Accuracy: 482 0.3877551020408163\n",
      "Accuracy: 483 0.3877551020408163\n",
      "Accuracy: 484 0.3877551020408163\n",
      "Accuracy: 485 0.3877551020408163\n",
      "Accuracy: 486 0.3877551020408163\n",
      "Accuracy: 487 0.3877551020408163\n",
      "Accuracy: 488 0.3877551020408163\n",
      "Accuracy: 489 0.3877551020408163\n",
      "Accuracy: 490 0.3877551020408163\n",
      "Accuracy: 491 0.3877551020408163\n",
      "Accuracy: 492 0.3877551020408163\n",
      "Accuracy: 493 0.3877551020408163\n",
      "Accuracy: 494 0.3877551020408163\n",
      "Accuracy: 495 0.3877551020408163\n",
      "Accuracy: 496 0.3877551020408163\n",
      "Accuracy: 497 0.3877551020408163\n",
      "Accuracy: 498 0.3877551020408163\n",
      "Accuracy: 499 0.3877551020408163\n",
      "Accuracy: 500 0.3877551020408163\n",
      "Accuracy: 501 0.3877551020408163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 502 0.3877551020408163\n",
      "Accuracy: 503 0.3877551020408163\n",
      "Accuracy: 504 0.3877551020408163\n",
      "Accuracy: 505 0.3877551020408163\n",
      "Accuracy: 506 0.3877551020408163\n",
      "Accuracy: 507 0.3877551020408163\n",
      "Accuracy: 508 0.3877551020408163\n",
      "Accuracy: 509 0.3877551020408163\n",
      "Accuracy: 510 0.3877551020408163\n",
      "Accuracy: 511 0.3877551020408163\n",
      "Accuracy: 512 0.3877551020408163\n",
      "Accuracy: 513 0.3877551020408163\n",
      "Accuracy: 514 0.3877551020408163\n",
      "Accuracy: 515 0.3877551020408163\n",
      "Accuracy: 516 0.3877551020408163\n",
      "Accuracy: 517 0.3877551020408163\n",
      "Accuracy: 518 0.3877551020408163\n",
      "Accuracy: 519 0.3877551020408163\n",
      "Accuracy: 520 0.3877551020408163\n",
      "Accuracy: 521 0.3877551020408163\n",
      "Accuracy: 522 0.3877551020408163\n",
      "Accuracy: 523 0.3877551020408163\n",
      "Accuracy: 524 0.3877551020408163\n",
      "Accuracy: 525 0.3877551020408163\n",
      "Accuracy: 526 0.3877551020408163\n",
      "Accuracy: 527 0.3877551020408163\n",
      "Accuracy: 528 0.3877551020408163\n",
      "Accuracy: 529 0.3877551020408163\n",
      "Accuracy: 530 0.3877551020408163\n",
      "Accuracy: 531 0.3877551020408163\n",
      "Accuracy: 532 0.3877551020408163\n",
      "Accuracy: 533 0.3877551020408163\n",
      "Accuracy: 534 0.3877551020408163\n",
      "Accuracy: 535 0.3877551020408163\n",
      "Accuracy: 536 0.3877551020408163\n",
      "Accuracy: 537 0.3877551020408163\n",
      "Accuracy: 538 0.3877551020408163\n",
      "Accuracy: 539 0.3877551020408163\n",
      "Accuracy: 540 0.3877551020408163\n",
      "Accuracy: 541 0.3877551020408163\n",
      "Accuracy: 542 0.3877551020408163\n",
      "Accuracy: 543 0.3877551020408163\n",
      "Accuracy: 544 0.3877551020408163\n",
      "Accuracy: 545 0.3877551020408163\n",
      "Accuracy: 546 0.3877551020408163\n",
      "Accuracy: 547 0.3877551020408163\n",
      "Accuracy: 548 0.3877551020408163\n",
      "Accuracy: 549 0.3877551020408163\n",
      "Accuracy: 550 0.3877551020408163\n",
      "Accuracy: 551 0.3877551020408163\n",
      "Accuracy: 552 0.3877551020408163\n",
      "Accuracy: 553 0.3877551020408163\n",
      "Accuracy: 554 0.3877551020408163\n",
      "Accuracy: 555 0.3877551020408163\n",
      "Accuracy: 556 0.3877551020408163\n",
      "Accuracy: 557 0.3877551020408163\n",
      "Accuracy: 558 0.3877551020408163\n",
      "Accuracy: 559 0.3877551020408163\n",
      "Accuracy: 560 0.3877551020408163\n",
      "Accuracy: 561 0.3877551020408163\n",
      "Accuracy: 562 0.3877551020408163\n",
      "Accuracy: 563 0.3877551020408163\n",
      "Accuracy: 564 0.3877551020408163\n",
      "Accuracy: 565 0.3877551020408163\n",
      "Accuracy: 566 0.3877551020408163\n",
      "Accuracy: 567 0.3877551020408163\n",
      "Accuracy: 568 0.3877551020408163\n",
      "Accuracy: 569 0.3877551020408163\n",
      "Accuracy: 570 0.3877551020408163\n",
      "Accuracy: 571 0.3877551020408163\n",
      "Accuracy: 572 0.3877551020408163\n",
      "Accuracy: 573 0.3877551020408163\n",
      "Accuracy: 574 0.3877551020408163\n",
      "Accuracy: 575 0.3877551020408163\n",
      "Accuracy: 576 0.3877551020408163\n",
      "Accuracy: 577 0.3877551020408163\n",
      "Accuracy: 578 0.3877551020408163\n",
      "Accuracy: 579 0.3877551020408163\n",
      "Accuracy: 580 0.3877551020408163\n",
      "Accuracy: 581 0.3877551020408163\n",
      "Accuracy: 582 0.3877551020408163\n",
      "Accuracy: 583 0.3877551020408163\n",
      "Accuracy: 584 0.3877551020408163\n",
      "Accuracy: 585 0.3877551020408163\n",
      "Accuracy: 586 0.3877551020408163\n",
      "Accuracy: 587 0.3877551020408163\n",
      "Accuracy: 588 0.3877551020408163\n",
      "max 0\n",
      "max_val 0.8707482993197279\n",
      "max 1\n",
      "max_val 0.8639455782312925\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "Acc = []\n",
    "for x in range(len(trainingSet)):\n",
    "    model = KNeighborsClassifier(n_neighbors=x+1)\n",
    "    model.fit(features,trainingSet['Region_RC'])\n",
    "    \n",
    "    predicted = []\n",
    "    for i in range(len(testSet)):\n",
    "        income = testSet.iloc[i].Income\n",
    "        age = testSet.iloc[i].Age\n",
    "        occupation = testSet.iloc[i].Occupation_RC\n",
    "        education = testSet.iloc[i].Education_RC\n",
    "        gender = testSet.iloc[i].Gender_RC\n",
    "        predicted.__iadd__(model.predict([[income,age,occupation,education,gender]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    print(\"Accuracy:\",x+1,metrics.accuracy_score(testSet.Region_RC, predicted))\n",
    "    Acc.append(metrics.accuracy_score(testSet.Region_RC, predicted))\n",
    "max_value = max(Acc)\n",
    "max_index = Acc.index(max_value)\n",
    "print('max',max_index)\n",
    "print('max_val',max_value)\n",
    "if Acc.index(max_value) == 0: #Crossvalidation is prefered so we're excluding the 1 neighbour value if it's the highest\n",
    "    Acc.remove(Acc[0])\n",
    "    max_value = max(Acc)\n",
    "    max_index = Acc.index(max_value)\n",
    "    print('max',max_index)\n",
    "    print('max_val',max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8435374149659864,\n",
       " 0.8639455782312925,\n",
       " 0.7891156462585034,\n",
       " 0.7755102040816326,\n",
       " 0.7755102040816326,\n",
       " 0.8163265306122449,\n",
       " 0.7959183673469388,\n",
       " 0.7755102040816326,\n",
       " 0.7210884353741497,\n",
       " 0.7482993197278912,\n",
       " 0.7551020408163265,\n",
       " 0.7482993197278912,\n",
       " 0.7414965986394558,\n",
       " 0.6870748299319728,\n",
       " 0.7074829931972789,\n",
       " 0.6802721088435374,\n",
       " 0.6938775510204082,\n",
       " 0.673469387755102,\n",
       " 0.673469387755102,\n",
       " 0.6530612244897959,\n",
       " 0.6462585034013606,\n",
       " 0.6462585034013606,\n",
       " 0.6326530612244898,\n",
       " 0.673469387755102,\n",
       " 0.6802721088435374,\n",
       " 0.6938775510204082,\n",
       " 0.7006802721088435,\n",
       " 0.673469387755102,\n",
       " 0.6802721088435374,\n",
       " 0.673469387755102,\n",
       " 0.6666666666666666,\n",
       " 0.6462585034013606,\n",
       " 0.6666666666666666,\n",
       " 0.6258503401360545,\n",
       " 0.6326530612244898,\n",
       " 0.6258503401360545,\n",
       " 0.6530612244897959,\n",
       " 0.6394557823129252,\n",
       " 0.6530612244897959,\n",
       " 0.6394557823129252,\n",
       " 0.6598639455782312,\n",
       " 0.6530612244897959,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.673469387755102,\n",
       " 0.6802721088435374,\n",
       " 0.673469387755102,\n",
       " 0.673469387755102,\n",
       " 0.6530612244897959,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6190476190476191,\n",
       " 0.6190476190476191,\n",
       " 0.6258503401360545,\n",
       " 0.6258503401360545,\n",
       " 0.6258503401360545,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6462585034013606,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6462585034013606,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.5986394557823129,\n",
       " 0.5850340136054422,\n",
       " 0.5850340136054422,\n",
       " 0.5782312925170068,\n",
       " 0.5782312925170068,\n",
       " 0.5714285714285714,\n",
       " 0.5850340136054422,\n",
       " 0.5850340136054422,\n",
       " 0.5986394557823129,\n",
       " 0.5918367346938775,\n",
       " 0.5986394557823129,\n",
       " 0.6190476190476191,\n",
       " 0.6190476190476191,\n",
       " 0.6190476190476191,\n",
       " 0.6258503401360545,\n",
       " 0.6122448979591837,\n",
       " 0.6190476190476191,\n",
       " 0.6122448979591837,\n",
       " 0.6122448979591837,\n",
       " 0.6326530612244898,\n",
       " 0.6258503401360545,\n",
       " 0.6394557823129252,\n",
       " 0.6258503401360545,\n",
       " 0.6666666666666666,\n",
       " 0.6666666666666666,\n",
       " 0.6802721088435374,\n",
       " 0.6802721088435374,\n",
       " 0.6870748299319728,\n",
       " 0.6870748299319728,\n",
       " 0.6870748299319728,\n",
       " 0.6870748299319728,\n",
       " 0.673469387755102,\n",
       " 0.6870748299319728,\n",
       " 0.6870748299319728,\n",
       " 0.6870748299319728,\n",
       " 0.6938775510204082,\n",
       " 0.6938775510204082,\n",
       " 0.6938775510204082,\n",
       " 0.6802721088435374,\n",
       " 0.6802721088435374,\n",
       " 0.6802721088435374,\n",
       " 0.673469387755102,\n",
       " 0.673469387755102,\n",
       " 0.673469387755102,\n",
       " 0.6802721088435374,\n",
       " 0.6598639455782312,\n",
       " 0.6870748299319728,\n",
       " 0.6666666666666666,\n",
       " 0.6598639455782312,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6462585034013606,\n",
       " 0.6462585034013606,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6462585034013606,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6530612244897959,\n",
       " 0.6462585034013606,\n",
       " 0.6462585034013606,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6258503401360545,\n",
       " 0.6258503401360545,\n",
       " 0.6190476190476191,\n",
       " 0.6326530612244898,\n",
       " 0.6122448979591837,\n",
       " 0.6326530612244898,\n",
       " 0.6258503401360545,\n",
       " 0.6326530612244898,\n",
       " 0.6122448979591837,\n",
       " 0.6326530612244898,\n",
       " 0.6258503401360545,\n",
       " 0.6326530612244898,\n",
       " 0.6122448979591837,\n",
       " 0.6190476190476191,\n",
       " 0.6190476190476191,\n",
       " 0.6394557823129252,\n",
       " 0.6462585034013606,\n",
       " 0.6462585034013606,\n",
       " 0.6462585034013606,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6394557823129252,\n",
       " 0.6326530612244898,\n",
       " 0.6530612244897959,\n",
       " 0.6394557823129252,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6530612244897959,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6326530612244898,\n",
       " 0.6054421768707483,\n",
       " 0.6394557823129252,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.6054421768707483,\n",
       " 0.5782312925170068,\n",
       " 0.5782312925170068,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5714285714285714,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5578231292517006,\n",
       " 0.5102040816326531,\n",
       " 0.5034013605442177,\n",
       " 0.46258503401360546,\n",
       " 0.42857142857142855,\n",
       " 0.40816326530612246,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163,\n",
       " 0.3877551020408163]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8435374149659864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "model = KNeighborsClassifier(n_neighbors=max_index+1)\n",
    "model.fit(features,trainingSet['Region_RC'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    age = testSet.iloc[i].Age\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    predicted.__iadd__(model.predict([[income,age,occupation,education,gender]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Region_RC, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>638</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>North America</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>430</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>469</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Europe</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>557</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>538</td>\n",
       "      <td>80000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>North America</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>797</td>\n",
       "      <td>60000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>North America</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>443</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Europe</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Europe</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>100000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Pacific</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars         Region   Age  Marital_Status_RC  \\\n",
       "638   70000.0         3     2  North America  74.0                  1   \n",
       "430   30000.0         3     2        Pacific  55.0                  1   \n",
       "469   30000.0         1     0         Europe  65.0                  0   \n",
       "18    40000.0         2     1         Europe  35.0                  1   \n",
       "557   40000.0         3     0  North America  31.0                  0   \n",
       "..        ...       ...   ...            ...   ...                ...   \n",
       "538   80000.0         4     0  North America  42.0                  0   \n",
       "797   60000.0         0     1  North America  27.0                  1   \n",
       "443   40000.0         1     1         Europe  43.0                  0   \n",
       "180   10000.0         1     0         Europe  44.0                  1   \n",
       "167  100000.0         0     3        Pacific  35.0                  1   \n",
       "\n",
       "     Gender_RC  Education_RC  Occupation_RC  Home_Owner_RC  \\\n",
       "638          1             4              4              1   \n",
       "430          0             2              0              1   \n",
       "469          0             0              1              1   \n",
       "18           1             1              1              1   \n",
       "557          0             1              1              1   \n",
       "..         ...           ...            ...            ...   \n",
       "538          0             0              4              1   \n",
       "797          1             1              0              1   \n",
       "443          0             0              0              1   \n",
       "180          1             4              3              1   \n",
       "167          1             2              4              1   \n",
       "\n",
       "     Commute_Distance_RC Purchased Bike  Region_RC  \n",
       "638                   10            Yes          1  \n",
       "430                   10             No          2  \n",
       "469                    1             No          0  \n",
       "18                     2            Yes          0  \n",
       "557                    2             No          1  \n",
       "..                   ...            ...        ...  \n",
       "538                    1             No          1  \n",
       "797                   10            Yes          1  \n",
       "443                    1            Yes          0  \n",
       "180                    1             No          0  \n",
       "167                   11             No          2  \n",
       "\n",
       "[147 rows x 13 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further testing\n",
    "what happens if we add more columns to the fit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(zip(trainingSet['Income'],trainingSet['Age'],trainingSet['Occupation_RC'],trainingSet['Education_RC'],trainingSet['Gender_RC'],trainingSet['Children'],trainingSet['Cars'],trainingSet['Marital_Status_RC'],trainingSet['Home_Owner_RC'],trainingSet['Commute_Distance_RC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1 0.9319727891156463\n",
      "Accuracy: 2 0.8707482993197279\n",
      "Accuracy: 3 0.8639455782312925\n",
      "Accuracy: 4 0.8095238095238095\n",
      "Accuracy: 5 0.782312925170068\n",
      "Accuracy: 6 0.7482993197278912\n",
      "Accuracy: 7 0.782312925170068\n",
      "Accuracy: 8 0.7687074829931972\n",
      "Accuracy: 9 0.7687074829931972\n",
      "Accuracy: 10 0.7482993197278912\n",
      "Accuracy: 11 0.782312925170068\n",
      "Accuracy: 12 0.7687074829931972\n",
      "Accuracy: 13 0.7755102040816326\n",
      "Accuracy: 14 0.7414965986394558\n",
      "Accuracy: 15 0.7278911564625851\n",
      "Accuracy: 16 0.7414965986394558\n",
      "Accuracy: 17 0.7210884353741497\n",
      "Accuracy: 18 0.7278911564625851\n",
      "Accuracy: 19 0.7210884353741497\n",
      "Accuracy: 20 0.7074829931972789\n",
      "Accuracy: 21 0.7074829931972789\n",
      "Accuracy: 22 0.6802721088435374\n",
      "Accuracy: 23 0.6938775510204082\n",
      "Accuracy: 24 0.6666666666666666\n",
      "Accuracy: 25 0.6870748299319728\n",
      "Accuracy: 26 0.6802721088435374\n",
      "Accuracy: 27 0.7006802721088435\n",
      "Accuracy: 28 0.6938775510204082\n",
      "Accuracy: 29 0.6870748299319728\n",
      "Accuracy: 30 0.6870748299319728\n",
      "Accuracy: 31 0.6938775510204082\n",
      "Accuracy: 32 0.6530612244897959\n",
      "Accuracy: 33 0.6530612244897959\n",
      "Accuracy: 34 0.6666666666666666\n",
      "Accuracy: 35 0.6462585034013606\n",
      "Accuracy: 36 0.6530612244897959\n",
      "Accuracy: 37 0.6394557823129252\n",
      "Accuracy: 38 0.6530612244897959\n",
      "Accuracy: 39 0.6530612244897959\n",
      "Accuracy: 40 0.6530612244897959\n",
      "Accuracy: 41 0.6326530612244898\n",
      "Accuracy: 42 0.6530612244897959\n",
      "Accuracy: 43 0.6598639455782312\n",
      "Accuracy: 44 0.6598639455782312\n",
      "Accuracy: 45 0.6666666666666666\n",
      "Accuracy: 46 0.673469387755102\n",
      "Accuracy: 47 0.6666666666666666\n",
      "Accuracy: 48 0.6666666666666666\n",
      "Accuracy: 49 0.6666666666666666\n",
      "Accuracy: 50 0.6530612244897959\n",
      "Accuracy: 51 0.6530612244897959\n",
      "Accuracy: 52 0.6394557823129252\n",
      "Accuracy: 53 0.6530612244897959\n",
      "Accuracy: 54 0.6326530612244898\n",
      "Accuracy: 55 0.6326530612244898\n",
      "Accuracy: 56 0.6258503401360545\n",
      "Accuracy: 57 0.6258503401360545\n",
      "Accuracy: 58 0.6258503401360545\n",
      "Accuracy: 59 0.6394557823129252\n",
      "Accuracy: 60 0.6462585034013606\n",
      "Accuracy: 61 0.6462585034013606\n",
      "Accuracy: 62 0.6326530612244898\n",
      "Accuracy: 63 0.6462585034013606\n",
      "Accuracy: 64 0.6394557823129252\n",
      "Accuracy: 65 0.6394557823129252\n",
      "Accuracy: 66 0.6394557823129252\n",
      "Accuracy: 67 0.6530612244897959\n",
      "Accuracy: 68 0.6394557823129252\n",
      "Accuracy: 69 0.6258503401360545\n",
      "Accuracy: 70 0.6326530612244898\n",
      "Accuracy: 71 0.6258503401360545\n",
      "Accuracy: 72 0.6394557823129252\n",
      "Accuracy: 73 0.6598639455782312\n",
      "Accuracy: 74 0.6462585034013606\n",
      "Accuracy: 75 0.6190476190476191\n",
      "Accuracy: 76 0.6054421768707483\n",
      "Accuracy: 77 0.6054421768707483\n",
      "Accuracy: 78 0.5918367346938775\n",
      "Accuracy: 79 0.5918367346938775\n",
      "Accuracy: 80 0.5850340136054422\n",
      "Accuracy: 81 0.6122448979591837\n",
      "Accuracy: 82 0.5986394557823129\n",
      "Accuracy: 83 0.6258503401360545\n",
      "Accuracy: 84 0.6122448979591837\n",
      "Accuracy: 85 0.6122448979591837\n",
      "Accuracy: 86 0.6190476190476191\n",
      "Accuracy: 87 0.6326530612244898\n",
      "Accuracy: 88 0.6258503401360545\n",
      "Accuracy: 89 0.6326530612244898\n",
      "Accuracy: 90 0.6326530612244898\n",
      "Accuracy: 91 0.6326530612244898\n",
      "Accuracy: 92 0.6054421768707483\n",
      "Accuracy: 93 0.6122448979591837\n",
      "Accuracy: 94 0.6122448979591837\n",
      "Accuracy: 95 0.6326530612244898\n",
      "Accuracy: 96 0.6462585034013606\n",
      "Accuracy: 97 0.6326530612244898\n",
      "Accuracy: 98 0.6666666666666666\n",
      "Accuracy: 99 0.6530612244897959\n",
      "Accuracy: 100 0.673469387755102\n",
      "Accuracy: 101 0.673469387755102\n",
      "Accuracy: 102 0.6802721088435374\n",
      "Accuracy: 103 0.6802721088435374\n",
      "Accuracy: 104 0.6870748299319728\n",
      "Accuracy: 105 0.6870748299319728\n",
      "Accuracy: 106 0.6870748299319728\n",
      "Accuracy: 107 0.6938775510204082\n",
      "Accuracy: 108 0.6938775510204082\n",
      "Accuracy: 109 0.6938775510204082\n",
      "Accuracy: 110 0.7006802721088435\n",
      "Accuracy: 111 0.6938775510204082\n",
      "Accuracy: 112 0.6870748299319728\n",
      "Accuracy: 113 0.6938775510204082\n",
      "Accuracy: 114 0.6938775510204082\n",
      "Accuracy: 115 0.7006802721088435\n",
      "Accuracy: 116 0.6870748299319728\n",
      "Accuracy: 117 0.6870748299319728\n",
      "Accuracy: 118 0.6870748299319728\n",
      "Accuracy: 119 0.6870748299319728\n",
      "Accuracy: 120 0.6870748299319728\n",
      "Accuracy: 121 0.7006802721088435\n",
      "Accuracy: 122 0.6870748299319728\n",
      "Accuracy: 123 0.6870748299319728\n",
      "Accuracy: 124 0.6802721088435374\n",
      "Accuracy: 125 0.673469387755102\n",
      "Accuracy: 126 0.6666666666666666\n",
      "Accuracy: 127 0.6530612244897959\n",
      "Accuracy: 128 0.6530612244897959\n",
      "Accuracy: 129 0.6530612244897959\n",
      "Accuracy: 130 0.6530612244897959\n",
      "Accuracy: 131 0.6462585034013606\n",
      "Accuracy: 132 0.6394557823129252\n",
      "Accuracy: 133 0.6462585034013606\n",
      "Accuracy: 134 0.6394557823129252\n",
      "Accuracy: 135 0.6462585034013606\n",
      "Accuracy: 136 0.6530612244897959\n",
      "Accuracy: 137 0.6530612244897959\n",
      "Accuracy: 138 0.6598639455782312\n",
      "Accuracy: 139 0.6394557823129252\n",
      "Accuracy: 140 0.6394557823129252\n",
      "Accuracy: 141 0.6394557823129252\n",
      "Accuracy: 142 0.6394557823129252\n",
      "Accuracy: 143 0.6394557823129252\n",
      "Accuracy: 144 0.6394557823129252\n",
      "Accuracy: 145 0.6394557823129252\n",
      "Accuracy: 146 0.6394557823129252\n",
      "Accuracy: 147 0.6394557823129252\n",
      "Accuracy: 148 0.6394557823129252\n",
      "Accuracy: 149 0.6394557823129252\n",
      "Accuracy: 150 0.6462585034013606\n",
      "Accuracy: 151 0.6326530612244898\n",
      "Accuracy: 152 0.6326530612244898\n",
      "Accuracy: 153 0.6326530612244898\n",
      "Accuracy: 154 0.6394557823129252\n",
      "Accuracy: 155 0.6394557823129252\n",
      "Accuracy: 156 0.6394557823129252\n",
      "Accuracy: 157 0.6394557823129252\n",
      "Accuracy: 158 0.6394557823129252\n",
      "Accuracy: 159 0.6394557823129252\n",
      "Accuracy: 160 0.6394557823129252\n",
      "Accuracy: 161 0.6394557823129252\n",
      "Accuracy: 162 0.6394557823129252\n",
      "Accuracy: 163 0.6394557823129252\n",
      "Accuracy: 164 0.6394557823129252\n",
      "Accuracy: 165 0.6326530612244898\n",
      "Accuracy: 166 0.6394557823129252\n",
      "Accuracy: 167 0.6394557823129252\n",
      "Accuracy: 168 0.6394557823129252\n",
      "Accuracy: 169 0.6394557823129252\n",
      "Accuracy: 170 0.6394557823129252\n",
      "Accuracy: 171 0.6394557823129252\n",
      "Accuracy: 172 0.6394557823129252\n",
      "Accuracy: 173 0.6394557823129252\n",
      "Accuracy: 174 0.6462585034013606\n",
      "Accuracy: 175 0.6394557823129252\n",
      "Accuracy: 176 0.6394557823129252\n",
      "Accuracy: 177 0.6394557823129252\n",
      "Accuracy: 178 0.6394557823129252\n",
      "Accuracy: 179 0.6394557823129252\n",
      "Accuracy: 180 0.6394557823129252\n",
      "Accuracy: 181 0.6394557823129252\n",
      "Accuracy: 182 0.6394557823129252\n",
      "Accuracy: 183 0.6394557823129252\n",
      "Accuracy: 184 0.6394557823129252\n",
      "Accuracy: 185 0.6394557823129252\n",
      "Accuracy: 186 0.6394557823129252\n",
      "Accuracy: 187 0.6394557823129252\n",
      "Accuracy: 188 0.6394557823129252\n",
      "Accuracy: 189 0.6394557823129252\n",
      "Accuracy: 190 0.6394557823129252\n",
      "Accuracy: 191 0.6394557823129252\n",
      "Accuracy: 192 0.6394557823129252\n",
      "Accuracy: 193 0.6394557823129252\n",
      "Accuracy: 194 0.6394557823129252\n",
      "Accuracy: 195 0.6394557823129252\n",
      "Accuracy: 196 0.6394557823129252\n",
      "Accuracy: 197 0.6394557823129252\n",
      "Accuracy: 198 0.6394557823129252\n",
      "Accuracy: 199 0.6394557823129252\n",
      "Accuracy: 200 0.6394557823129252\n",
      "Accuracy: 201 0.6394557823129252\n",
      "Accuracy: 202 0.6394557823129252\n",
      "Accuracy: 203 0.6394557823129252\n",
      "Accuracy: 204 0.6394557823129252\n",
      "Accuracy: 205 0.6394557823129252\n",
      "Accuracy: 206 0.6394557823129252\n",
      "Accuracy: 207 0.6394557823129252\n",
      "Accuracy: 208 0.6394557823129252\n",
      "Accuracy: 209 0.6394557823129252\n",
      "Accuracy: 210 0.6394557823129252\n",
      "Accuracy: 211 0.6394557823129252\n",
      "Accuracy: 212 0.6394557823129252\n",
      "Accuracy: 213 0.6394557823129252\n",
      "Accuracy: 214 0.6394557823129252\n",
      "Accuracy: 215 0.6394557823129252\n",
      "Accuracy: 216 0.6394557823129252\n",
      "Accuracy: 217 0.6394557823129252\n",
      "Accuracy: 218 0.6394557823129252\n",
      "Accuracy: 219 0.6394557823129252\n",
      "Accuracy: 220 0.6394557823129252\n",
      "Accuracy: 221 0.6394557823129252\n",
      "Accuracy: 222 0.6394557823129252\n",
      "Accuracy: 223 0.6394557823129252\n",
      "Accuracy: 224 0.6394557823129252\n",
      "Accuracy: 225 0.6394557823129252\n",
      "Accuracy: 226 0.6394557823129252\n",
      "Accuracy: 227 0.6394557823129252\n",
      "Accuracy: 228 0.6394557823129252\n",
      "Accuracy: 229 0.6394557823129252\n",
      "Accuracy: 230 0.6394557823129252\n",
      "Accuracy: 231 0.6394557823129252\n",
      "Accuracy: 232 0.6394557823129252\n",
      "Accuracy: 233 0.6394557823129252\n",
      "Accuracy: 234 0.6394557823129252\n",
      "Accuracy: 235 0.6394557823129252\n",
      "Accuracy: 236 0.6394557823129252\n",
      "Accuracy: 237 0.6394557823129252\n",
      "Accuracy: 238 0.6394557823129252\n",
      "Accuracy: 239 0.6394557823129252\n",
      "Accuracy: 240 0.6394557823129252\n",
      "Accuracy: 241 0.6462585034013606\n",
      "Accuracy: 242 0.6394557823129252\n",
      "Accuracy: 243 0.6394557823129252\n",
      "Accuracy: 244 0.6462585034013606\n",
      "Accuracy: 245 0.6530612244897959\n",
      "Accuracy: 246 0.6530612244897959\n",
      "Accuracy: 247 0.6530612244897959\n",
      "Accuracy: 248 0.6530612244897959\n",
      "Accuracy: 249 0.6530612244897959\n",
      "Accuracy: 250 0.6462585034013606\n",
      "Accuracy: 251 0.6462585034013606\n",
      "Accuracy: 252 0.6462585034013606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 253 0.6394557823129252\n",
      "Accuracy: 254 0.6394557823129252\n",
      "Accuracy: 255 0.6462585034013606\n",
      "Accuracy: 256 0.6462585034013606\n",
      "Accuracy: 257 0.6530612244897959\n",
      "Accuracy: 258 0.6394557823129252\n",
      "Accuracy: 259 0.6394557823129252\n",
      "Accuracy: 260 0.6394557823129252\n",
      "Accuracy: 261 0.6394557823129252\n",
      "Accuracy: 262 0.6326530612244898\n",
      "Accuracy: 263 0.6326530612244898\n",
      "Accuracy: 264 0.6326530612244898\n",
      "Accuracy: 265 0.6326530612244898\n",
      "Accuracy: 266 0.6326530612244898\n",
      "Accuracy: 267 0.6326530612244898\n",
      "Accuracy: 268 0.6326530612244898\n",
      "Accuracy: 269 0.6326530612244898\n",
      "Accuracy: 270 0.6326530612244898\n",
      "Accuracy: 271 0.6326530612244898\n",
      "Accuracy: 272 0.6326530612244898\n",
      "Accuracy: 273 0.6326530612244898\n",
      "Accuracy: 274 0.6326530612244898\n",
      "Accuracy: 275 0.6326530612244898\n",
      "Accuracy: 276 0.6326530612244898\n",
      "Accuracy: 277 0.6326530612244898\n",
      "Accuracy: 278 0.6326530612244898\n",
      "Accuracy: 279 0.6326530612244898\n",
      "Accuracy: 280 0.6326530612244898\n",
      "Accuracy: 281 0.6326530612244898\n",
      "Accuracy: 282 0.6326530612244898\n",
      "Accuracy: 283 0.6326530612244898\n",
      "Accuracy: 284 0.6326530612244898\n",
      "Accuracy: 285 0.6326530612244898\n",
      "Accuracy: 286 0.6326530612244898\n",
      "Accuracy: 287 0.6326530612244898\n",
      "Accuracy: 288 0.6326530612244898\n",
      "Accuracy: 289 0.6326530612244898\n",
      "Accuracy: 290 0.6326530612244898\n",
      "Accuracy: 291 0.6326530612244898\n",
      "Accuracy: 292 0.6326530612244898\n",
      "Accuracy: 293 0.6326530612244898\n",
      "Accuracy: 294 0.6326530612244898\n",
      "Accuracy: 295 0.6530612244897959\n",
      "Accuracy: 296 0.6394557823129252\n",
      "Accuracy: 297 0.6054421768707483\n",
      "Accuracy: 298 0.6054421768707483\n",
      "Accuracy: 299 0.6054421768707483\n",
      "Accuracy: 300 0.6054421768707483\n",
      "Accuracy: 301 0.6054421768707483\n",
      "Accuracy: 302 0.6054421768707483\n",
      "Accuracy: 303 0.6054421768707483\n",
      "Accuracy: 304 0.6054421768707483\n",
      "Accuracy: 305 0.6054421768707483\n",
      "Accuracy: 306 0.6054421768707483\n",
      "Accuracy: 307 0.6054421768707483\n",
      "Accuracy: 308 0.6054421768707483\n",
      "Accuracy: 309 0.6054421768707483\n",
      "Accuracy: 310 0.6054421768707483\n",
      "Accuracy: 311 0.6054421768707483\n",
      "Accuracy: 312 0.6054421768707483\n",
      "Accuracy: 313 0.6054421768707483\n",
      "Accuracy: 314 0.6054421768707483\n",
      "Accuracy: 315 0.6054421768707483\n",
      "Accuracy: 316 0.6054421768707483\n",
      "Accuracy: 317 0.6054421768707483\n",
      "Accuracy: 318 0.6054421768707483\n",
      "Accuracy: 319 0.6054421768707483\n",
      "Accuracy: 320 0.6054421768707483\n",
      "Accuracy: 321 0.6054421768707483\n",
      "Accuracy: 322 0.6054421768707483\n",
      "Accuracy: 323 0.6054421768707483\n",
      "Accuracy: 324 0.6054421768707483\n",
      "Accuracy: 325 0.6054421768707483\n",
      "Accuracy: 326 0.6054421768707483\n",
      "Accuracy: 327 0.6054421768707483\n",
      "Accuracy: 328 0.6054421768707483\n",
      "Accuracy: 329 0.6054421768707483\n",
      "Accuracy: 330 0.6054421768707483\n",
      "Accuracy: 331 0.6054421768707483\n",
      "Accuracy: 332 0.6054421768707483\n",
      "Accuracy: 333 0.6054421768707483\n",
      "Accuracy: 334 0.6054421768707483\n",
      "Accuracy: 335 0.6054421768707483\n",
      "Accuracy: 336 0.6054421768707483\n",
      "Accuracy: 337 0.6054421768707483\n",
      "Accuracy: 338 0.6054421768707483\n",
      "Accuracy: 339 0.6054421768707483\n",
      "Accuracy: 340 0.6054421768707483\n",
      "Accuracy: 341 0.6054421768707483\n",
      "Accuracy: 342 0.6054421768707483\n",
      "Accuracy: 343 0.6054421768707483\n",
      "Accuracy: 344 0.6054421768707483\n",
      "Accuracy: 345 0.6054421768707483\n",
      "Accuracy: 346 0.6054421768707483\n",
      "Accuracy: 347 0.6054421768707483\n",
      "Accuracy: 348 0.6054421768707483\n",
      "Accuracy: 349 0.6054421768707483\n",
      "Accuracy: 350 0.6054421768707483\n",
      "Accuracy: 351 0.6054421768707483\n",
      "Accuracy: 352 0.6054421768707483\n",
      "Accuracy: 353 0.6054421768707483\n",
      "Accuracy: 354 0.6054421768707483\n",
      "Accuracy: 355 0.6054421768707483\n",
      "Accuracy: 356 0.6054421768707483\n",
      "Accuracy: 357 0.6054421768707483\n",
      "Accuracy: 358 0.6054421768707483\n",
      "Accuracy: 359 0.6054421768707483\n",
      "Accuracy: 360 0.6054421768707483\n",
      "Accuracy: 361 0.6054421768707483\n",
      "Accuracy: 362 0.6054421768707483\n",
      "Accuracy: 363 0.6054421768707483\n",
      "Accuracy: 364 0.6054421768707483\n",
      "Accuracy: 365 0.6054421768707483\n",
      "Accuracy: 366 0.6054421768707483\n",
      "Accuracy: 367 0.6054421768707483\n",
      "Accuracy: 368 0.6054421768707483\n",
      "Accuracy: 369 0.6054421768707483\n",
      "Accuracy: 370 0.6054421768707483\n",
      "Accuracy: 371 0.6054421768707483\n",
      "Accuracy: 372 0.6054421768707483\n",
      "Accuracy: 373 0.6054421768707483\n",
      "Accuracy: 374 0.6054421768707483\n",
      "Accuracy: 375 0.6054421768707483\n",
      "Accuracy: 376 0.6054421768707483\n",
      "Accuracy: 377 0.6054421768707483\n",
      "Accuracy: 378 0.6054421768707483\n",
      "Accuracy: 379 0.6054421768707483\n",
      "Accuracy: 380 0.6054421768707483\n",
      "Accuracy: 381 0.6054421768707483\n",
      "Accuracy: 382 0.6054421768707483\n",
      "Accuracy: 383 0.6054421768707483\n",
      "Accuracy: 384 0.6054421768707483\n",
      "Accuracy: 385 0.6054421768707483\n",
      "Accuracy: 386 0.6054421768707483\n",
      "Accuracy: 387 0.6054421768707483\n",
      "Accuracy: 388 0.6054421768707483\n",
      "Accuracy: 389 0.6054421768707483\n",
      "Accuracy: 390 0.6054421768707483\n",
      "Accuracy: 391 0.6054421768707483\n",
      "Accuracy: 392 0.6054421768707483\n",
      "Accuracy: 393 0.6054421768707483\n",
      "Accuracy: 394 0.6054421768707483\n",
      "Accuracy: 395 0.6054421768707483\n",
      "Accuracy: 396 0.6054421768707483\n",
      "Accuracy: 397 0.6054421768707483\n",
      "Accuracy: 398 0.6054421768707483\n",
      "Accuracy: 399 0.6054421768707483\n",
      "Accuracy: 400 0.6054421768707483\n",
      "Accuracy: 401 0.6054421768707483\n",
      "Accuracy: 402 0.6054421768707483\n",
      "Accuracy: 403 0.6054421768707483\n",
      "Accuracy: 404 0.6054421768707483\n",
      "Accuracy: 405 0.6054421768707483\n",
      "Accuracy: 406 0.6054421768707483\n",
      "Accuracy: 407 0.6054421768707483\n",
      "Accuracy: 408 0.5714285714285714\n",
      "Accuracy: 409 0.5714285714285714\n",
      "Accuracy: 410 0.5714285714285714\n",
      "Accuracy: 411 0.5238095238095238\n",
      "Accuracy: 412 0.5170068027210885\n",
      "Accuracy: 413 0.5170068027210885\n",
      "Accuracy: 414 0.5034013605442177\n",
      "Accuracy: 415 0.5034013605442177\n",
      "Accuracy: 416 0.48299319727891155\n",
      "Accuracy: 417 0.48299319727891155\n",
      "Accuracy: 418 0.46258503401360546\n",
      "Accuracy: 419 0.46258503401360546\n",
      "Accuracy: 420 0.4557823129251701\n",
      "Accuracy: 421 0.4557823129251701\n",
      "Accuracy: 422 0.4421768707482993\n",
      "Accuracy: 423 0.40816326530612246\n",
      "Accuracy: 424 0.3945578231292517\n",
      "Accuracy: 425 0.3877551020408163\n",
      "Accuracy: 426 0.3877551020408163\n",
      "Accuracy: 427 0.3877551020408163\n",
      "Accuracy: 428 0.3877551020408163\n",
      "Accuracy: 429 0.3877551020408163\n",
      "Accuracy: 430 0.3877551020408163\n",
      "Accuracy: 431 0.3877551020408163\n",
      "Accuracy: 432 0.3877551020408163\n",
      "Accuracy: 433 0.3877551020408163\n",
      "Accuracy: 434 0.3877551020408163\n",
      "Accuracy: 435 0.3877551020408163\n",
      "Accuracy: 436 0.3877551020408163\n",
      "Accuracy: 437 0.3877551020408163\n",
      "Accuracy: 438 0.3877551020408163\n",
      "Accuracy: 439 0.3877551020408163\n",
      "Accuracy: 440 0.3877551020408163\n",
      "Accuracy: 441 0.3877551020408163\n",
      "Accuracy: 442 0.3877551020408163\n",
      "Accuracy: 443 0.3877551020408163\n",
      "Accuracy: 444 0.3877551020408163\n",
      "Accuracy: 445 0.3877551020408163\n",
      "Accuracy: 446 0.3877551020408163\n",
      "Accuracy: 447 0.3877551020408163\n",
      "Accuracy: 448 0.3877551020408163\n",
      "Accuracy: 449 0.3877551020408163\n",
      "Accuracy: 450 0.3877551020408163\n",
      "Accuracy: 451 0.3877551020408163\n",
      "Accuracy: 452 0.3877551020408163\n",
      "Accuracy: 453 0.3877551020408163\n",
      "Accuracy: 454 0.3877551020408163\n",
      "Accuracy: 455 0.3877551020408163\n",
      "Accuracy: 456 0.3877551020408163\n",
      "Accuracy: 457 0.3877551020408163\n",
      "Accuracy: 458 0.3877551020408163\n",
      "Accuracy: 459 0.3877551020408163\n",
      "Accuracy: 460 0.3877551020408163\n",
      "Accuracy: 461 0.3877551020408163\n",
      "Accuracy: 462 0.3877551020408163\n",
      "Accuracy: 463 0.3877551020408163\n",
      "Accuracy: 464 0.3877551020408163\n",
      "Accuracy: 465 0.3877551020408163\n",
      "Accuracy: 466 0.3877551020408163\n",
      "Accuracy: 467 0.3877551020408163\n",
      "Accuracy: 468 0.3877551020408163\n",
      "Accuracy: 469 0.3877551020408163\n",
      "Accuracy: 470 0.3877551020408163\n",
      "Accuracy: 471 0.3877551020408163\n",
      "Accuracy: 472 0.3877551020408163\n",
      "Accuracy: 473 0.3877551020408163\n",
      "Accuracy: 474 0.3877551020408163\n",
      "Accuracy: 475 0.3877551020408163\n",
      "Accuracy: 476 0.3877551020408163\n",
      "Accuracy: 477 0.3877551020408163\n",
      "Accuracy: 478 0.3877551020408163\n",
      "Accuracy: 479 0.3877551020408163\n",
      "Accuracy: 480 0.3877551020408163\n",
      "Accuracy: 481 0.3877551020408163\n",
      "Accuracy: 482 0.3877551020408163\n",
      "Accuracy: 483 0.3877551020408163\n",
      "Accuracy: 484 0.3877551020408163\n",
      "Accuracy: 485 0.3877551020408163\n",
      "Accuracy: 486 0.3877551020408163\n",
      "Accuracy: 487 0.3877551020408163\n",
      "Accuracy: 488 0.3877551020408163\n",
      "Accuracy: 489 0.3877551020408163\n",
      "Accuracy: 490 0.3877551020408163\n",
      "Accuracy: 491 0.3877551020408163\n",
      "Accuracy: 492 0.3877551020408163\n",
      "Accuracy: 493 0.3877551020408163\n",
      "Accuracy: 494 0.3877551020408163\n",
      "Accuracy: 495 0.3877551020408163\n",
      "Accuracy: 496 0.3877551020408163\n",
      "Accuracy: 497 0.3877551020408163\n",
      "Accuracy: 498 0.3877551020408163\n",
      "Accuracy: 499 0.3877551020408163\n",
      "Accuracy: 500 0.3877551020408163\n",
      "Accuracy: 501 0.3877551020408163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 502 0.3877551020408163\n",
      "Accuracy: 503 0.3877551020408163\n",
      "Accuracy: 504 0.3877551020408163\n",
      "Accuracy: 505 0.3877551020408163\n",
      "Accuracy: 506 0.3877551020408163\n",
      "Accuracy: 507 0.3877551020408163\n",
      "Accuracy: 508 0.3877551020408163\n",
      "Accuracy: 509 0.3877551020408163\n",
      "Accuracy: 510 0.3877551020408163\n",
      "Accuracy: 511 0.3877551020408163\n",
      "Accuracy: 512 0.3877551020408163\n",
      "Accuracy: 513 0.3877551020408163\n",
      "Accuracy: 514 0.3877551020408163\n",
      "Accuracy: 515 0.3877551020408163\n",
      "Accuracy: 516 0.3877551020408163\n",
      "Accuracy: 517 0.3877551020408163\n",
      "Accuracy: 518 0.3877551020408163\n",
      "Accuracy: 519 0.3877551020408163\n",
      "Accuracy: 520 0.3877551020408163\n",
      "Accuracy: 521 0.3877551020408163\n",
      "Accuracy: 522 0.3877551020408163\n",
      "Accuracy: 523 0.3877551020408163\n",
      "Accuracy: 524 0.3877551020408163\n",
      "Accuracy: 525 0.3877551020408163\n",
      "Accuracy: 526 0.3877551020408163\n",
      "Accuracy: 527 0.3877551020408163\n",
      "Accuracy: 528 0.3877551020408163\n",
      "Accuracy: 529 0.3877551020408163\n",
      "Accuracy: 530 0.3877551020408163\n",
      "Accuracy: 531 0.3877551020408163\n",
      "Accuracy: 532 0.3877551020408163\n",
      "Accuracy: 533 0.3877551020408163\n",
      "Accuracy: 534 0.3877551020408163\n",
      "Accuracy: 535 0.3877551020408163\n",
      "Accuracy: 536 0.3877551020408163\n",
      "Accuracy: 537 0.3877551020408163\n",
      "Accuracy: 538 0.3877551020408163\n",
      "Accuracy: 539 0.3877551020408163\n",
      "Accuracy: 540 0.3877551020408163\n",
      "Accuracy: 541 0.3877551020408163\n",
      "Accuracy: 542 0.3877551020408163\n",
      "Accuracy: 543 0.3877551020408163\n",
      "Accuracy: 544 0.3877551020408163\n",
      "Accuracy: 545 0.3877551020408163\n",
      "Accuracy: 546 0.3877551020408163\n",
      "Accuracy: 547 0.3877551020408163\n",
      "Accuracy: 548 0.3877551020408163\n",
      "Accuracy: 549 0.3877551020408163\n",
      "Accuracy: 550 0.3877551020408163\n",
      "Accuracy: 551 0.3877551020408163\n",
      "Accuracy: 552 0.3877551020408163\n",
      "Accuracy: 553 0.3877551020408163\n",
      "Accuracy: 554 0.3877551020408163\n",
      "Accuracy: 555 0.3877551020408163\n",
      "Accuracy: 556 0.3877551020408163\n",
      "Accuracy: 557 0.3877551020408163\n",
      "Accuracy: 558 0.3877551020408163\n",
      "Accuracy: 559 0.3877551020408163\n",
      "Accuracy: 560 0.3877551020408163\n",
      "Accuracy: 561 0.3877551020408163\n",
      "Accuracy: 562 0.3877551020408163\n",
      "Accuracy: 563 0.3877551020408163\n",
      "Accuracy: 564 0.3877551020408163\n",
      "Accuracy: 565 0.3877551020408163\n",
      "Accuracy: 566 0.3877551020408163\n",
      "Accuracy: 567 0.3877551020408163\n",
      "Accuracy: 568 0.3877551020408163\n",
      "Accuracy: 569 0.3877551020408163\n",
      "Accuracy: 570 0.3877551020408163\n",
      "Accuracy: 571 0.3877551020408163\n",
      "Accuracy: 572 0.3877551020408163\n",
      "Accuracy: 573 0.3877551020408163\n",
      "Accuracy: 574 0.3877551020408163\n",
      "Accuracy: 575 0.3877551020408163\n",
      "Accuracy: 576 0.3877551020408163\n",
      "Accuracy: 577 0.3877551020408163\n",
      "Accuracy: 578 0.3877551020408163\n",
      "Accuracy: 579 0.3877551020408163\n",
      "Accuracy: 580 0.3877551020408163\n",
      "Accuracy: 581 0.3877551020408163\n",
      "Accuracy: 582 0.3877551020408163\n",
      "Accuracy: 583 0.3877551020408163\n",
      "Accuracy: 584 0.3877551020408163\n",
      "Accuracy: 585 0.3877551020408163\n",
      "Accuracy: 586 0.3877551020408163\n",
      "Accuracy: 587 0.3877551020408163\n",
      "Accuracy: 588 0.3877551020408163\n",
      "max 0\n",
      "max_val 0.9319727891156463\n",
      "max 0\n",
      "max_val 0.8707482993197279\n"
     ]
    }
   ],
   "source": [
    "Acc = []\n",
    "for x in range(len(trainingSet)):\n",
    "    model = KNeighborsClassifier(n_neighbors=x+1)\n",
    "    model.fit(features,trainingSet['Region_RC'])\n",
    "    predicted = []\n",
    "    for i in range(len(testSet)):\n",
    "        income = testSet.iloc[i].Income\n",
    "        age = testSet.iloc[i].Age\n",
    "        occupation = testSet.iloc[i].Occupation_RC\n",
    "        education = testSet.iloc[i].Education_RC\n",
    "        gender = testSet.iloc[i].Gender_RC\n",
    "        children = testSet.iloc[i].Children\n",
    "        cars = testSet.iloc[i].Cars\n",
    "        MS = testSet.iloc[i].Marital_Status_RC\n",
    "        home = testSet.iloc[i].Home_Owner_RC\n",
    "        CD = testSet.iloc[i].Commute_Distance_RC\n",
    "        predicted.__iadd__(model.predict([[income,age,occupation,education,gender,children,cars,MS,home,CD]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    print(\"Accuracy:\",x+1,metrics.accuracy_score(testSet.Region_RC, predicted))\n",
    "    Acc.append(metrics.accuracy_score(testSet.Region_RC, predicted))\n",
    "max_value = max(Acc)\n",
    "max_index = Acc.index(max_value)\n",
    "print('max',max_index)\n",
    "print('max_val',max_value)\n",
    "if Acc.index(max_value) == 0: #Crossvalidation is prefered so we're excluding the 1 neighbour value if it's the highest\n",
    "    Acc.remove(Acc[0])\n",
    "    max_value = max(Acc)\n",
    "    max_index = Acc.index(max_value)\n",
    "    print('max',max_index)\n",
    "    print('max_val',max_value)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9319727891156463\n",
      "max 0\n",
      "max_val 0.8707482993197279\n",
      "max 0\n",
      "max_val 0.8639455782312925\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=max_index+1) \n",
    "model.fit(features,trainingSet['Region_RC'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    age = testSet.iloc[i].Age\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    CD = testSet.iloc[i].Commute_Distance_RC\n",
    "    predicted.__iadd__(model.predict([[income,age,occupation,education,gender,children,cars,MS,home,CD]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Region_RC, predicted))\n",
    "max_value = max(Acc)\n",
    "max_index = Acc.index(max_value)\n",
    "print('max',max_index)\n",
    "print('max_val',max_value)\n",
    "if Acc.index(max_value) == 0: #Crossvalidation is prefered so we're excluding the 1 neighbour value if it's the highest\n",
    "    Acc.remove(Acc[0])\n",
    "    max_value = max(Acc)\n",
    "    max_index = Acc.index(max_value)\n",
    "    print('max',max_index)\n",
    "    print('max_val',max_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding all categories seems to add a bit of accuracy to ~86%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars Region   Age  Marital_Status_RC  Gender_RC  \\\n",
       "56    40000.0         0     0    NaN  38.0                  0          1   \n",
       "70   120000.0         0     4    NaN  36.0                  0          1   \n",
       "280   10000.0         3     2    NaN  43.0                  1          0   \n",
       "604   40000.0         0     2    NaN  27.0                  0          1   \n",
       "\n",
       "     Education_RC  Occupation_RC  Home_Owner_RC  Commute_Distance_RC  \\\n",
       "56              0              1              1                    1   \n",
       "70              3              2              1                   11   \n",
       "280             3              3              1                    1   \n",
       "604             2              0              1                   10   \n",
       "\n",
       "    Purchased Bike  Region_RC  \n",
       "56             Yes          0  \n",
       "70             Yes          0  \n",
       "280             No          0  \n",
       "604             No          0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filling the missing values\n",
    "set_region_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars Region   Age  Marital_Status_RC  Gender_RC  \\\n",
       "56    40000.0         0     0    NaN  38.0                  0          1   \n",
       "70   120000.0         0     4    NaN  36.0                  0          1   \n",
       "280   10000.0         3     2    NaN  43.0                  1          0   \n",
       "424       NaN         3     2    NaN  43.0                  1          0   \n",
       "604   40000.0         0     2    NaN  27.0                  0          1   \n",
       "\n",
       "     Education_RC  Occupation_RC  Home_Owner_RC  Commute_Distance_RC  \\\n",
       "56              0              1              1                    1   \n",
       "70              3              2              1                   11   \n",
       "280             3              3              1                    1   \n",
       "424             3              3              1                    1   \n",
       "604             2              0              1                   10   \n",
       "\n",
       "    Purchased Bike  \n",
       "56             Yes  \n",
       "70             Yes  \n",
       "280             No  \n",
       "424             No  \n",
       "604             No  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_RC[complete_RC['Region'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "range range(0, 4)\n",
      "pred loc 0\n",
      "predicted [0]\n",
      "i 1\n",
      "range range(0, 4)\n",
      "pred loc 2\n",
      "predicted [0, 2]\n",
      "i 2\n",
      "range range(0, 4)\n",
      "pred loc 0\n",
      "predicted [0, 2, 0]\n",
      "i 3\n",
      "range range(0, 4)\n",
      "pred loc 1\n",
      "predicted [0, 2, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(features,trainingSet['Region_RC'])\n",
    "for i in range(len(set_region_null)):\n",
    "    print(\"i\",i)\n",
    "    print(\"range\",range(len(set_region_null)))\n",
    "    income = set_region_null.iloc[i].Income\n",
    "    age = set_region_null.iloc[i].Age\n",
    "    occupation = set_region_null.iloc[i].Occupation_RC\n",
    "    education = set_region_null.iloc[i].Education_RC\n",
    "    gender = set_region_null.iloc[i].Gender_RC\n",
    "    children = set_region_null.iloc[i].Children\n",
    "    cars = set_region_null.iloc[i].Cars\n",
    "    MS = set_region_null.iloc[i].Marital_Status_RC\n",
    "    home = set_region_null.iloc[i].Home_Owner_RC\n",
    "    CD = set_region_null.iloc[i].Commute_Distance_RC\n",
    "    predicted.__iadd__(model.predict([[income,age,occupation,education,gender,children,cars,MS,home,CD]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    #bikes.at[bikes[bikes['Region_RC'] == 99].index[0],'Region_RC'] = mode_region\n",
    "    print('pred loc',predicted[i])\n",
    "    print(\"predicted\",predicted)\n",
    "    #set_region_null.at.index[i],'Region_RC' = predicted[i]\n",
    "    set_region_null.at[[set_region_null.index[i]],'Region_RC']= predicted[i] # 0:Europe, 1:NA,2:Pacific\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "range range(0, 4)\n",
      "pred loc 0\n",
      "predicted [0]\n",
      "i 1\n",
      "range range(0, 4)\n",
      "pred loc 2\n",
      "predicted [0, 2]\n",
      "i 2\n",
      "range range(0, 4)\n",
      "pred loc 0\n",
      "predicted [0, 2, 0]\n",
      "i 3\n",
      "range range(0, 4)\n",
      "pred loc 1\n",
      "predicted [0, 2, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "predicted = []\n",
    "model = KNeighborsClassifier(n_neighbors=2) #2 has the highest accuracy , determined by the next code block\n",
    "model.fit(features,trainingSet['Region_RC'])\n",
    "for i in range(len(set_region_null)):\n",
    "    print(\"i\",i)\n",
    "    print(\"range\",range(len(set_region_null)))\n",
    "    income = set_region_null.iloc[i].Income\n",
    "    age = set_region_null.iloc[i].Age\n",
    "    occupation = set_region_null.iloc[i].Occupation_RC\n",
    "    education = set_region_null.iloc[i].Education_RC\n",
    "    gender = set_region_null.iloc[i].Gender_RC\n",
    "    children = set_region_null.iloc[i].Children\n",
    "    cars = set_region_null.iloc[i].Cars\n",
    "    MS = set_region_null.iloc[i].Marital_Status_RC\n",
    "    home = set_region_null.iloc[i].Home_Owner_RC\n",
    "    CD = set_region_null.iloc[i].Commute_Distance_RC\n",
    "    predicted.__iadd__(model.predict([[income,age,occupation,education,gender,children,cars,MS,home,CD]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    #bikes.at[bikes[bikes['Region_RC'] == 99].index[0],'Region_RC'] = mode_region\n",
    "    print('pred loc',predicted[i])\n",
    "    print(\"predicted\",predicted)\n",
    "    #set_region_null.at.index[i],'Region_RC' = predicted[i]\n",
    "    set_region_null.at[[set_region_null.index[i]],'Region_RC']= predicted[i] # 0:Europe, 1:NA,2:Pacific\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars Region   Age  Marital_Status_RC  Gender_RC  \\\n",
       "56    40000.0         0     0    NaN  38.0                  0          1   \n",
       "70   120000.0         0     4    NaN  36.0                  0          1   \n",
       "280   10000.0         3     2    NaN  43.0                  1          0   \n",
       "424       NaN         3     2    NaN  43.0                  1          0   \n",
       "604   40000.0         0     2    NaN  27.0                  0          1   \n",
       "\n",
       "     Education_RC  Occupation_RC  Home_Owner_RC  Commute_Distance_RC  \\\n",
       "56              0              1              1                    1   \n",
       "70              3              2              1                   11   \n",
       "280             3              3              1                    1   \n",
       "424             3              3              1                    1   \n",
       "604             2              0              1                   10   \n",
       "\n",
       "    Purchased Bike  \n",
       "56             Yes  \n",
       "70             Yes  \n",
       "280             No  \n",
       "424             No  \n",
       "604             No  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#before\n",
    "complete_RC[complete_RC.Region.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_RC['Region'].fillna('Unknown', inplace = True) \n",
    "complete_RC['Region_RC'] = complete_RC['Region'].map( {'Europe': 0, 'Pacific': 1,'North America':2,'Unknown':99} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "range range(0, 5)\n",
      "income 40000.0\n",
      "predicted [0]\n",
      "i 1\n",
      "range range(0, 5)\n",
      "income 40000.0\n",
      "predicted [0, 0]\n",
      "i 2\n",
      "range range(0, 5)\n",
      "income 40000.0\n",
      "predicted [0, 0, 0]\n",
      "i 3\n",
      "range range(0, 5)\n",
      "income 40000.0\n",
      "predicted [0, 0, 0, 0]\n",
      "i 4\n",
      "range range(0, 5)\n",
      "income 40000.0\n",
      "predicted [0, 0, 0, 0, 0]\n",
      "i 0\n",
      "i 1\n",
      "i 2\n",
      "i 3\n",
      "i 4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predicted = []\n",
    "model = KNeighborsClassifier(n_neighbors=2) #2 has the highest accuracy , determined by the next code block\n",
    "model.fit(features,trainingSet['Region_RC'])\n",
    "for i in range(len(complete_RC[complete_RC['Region_RC']==99])):\n",
    "    print(\"i\",i)\n",
    "    print(\"range\",range(len(complete_RC[complete_RC['Region_RC']==99])))\n",
    "    income = complete_RC[complete_RC['Region_RC']==99].iloc[0].Income\n",
    "    print('income',income)\n",
    "    age = complete_RC[complete_RC['Region_RC']==99].iloc[0].Age\n",
    "    occupation = complete_RC[complete_RC['Region_RC']==99].iloc[0].Occupation_RC\n",
    "    education = complete_RC[complete_RC['Region_RC']==99].iloc[0].Education_RC\n",
    "    gender = complete_RC[complete_RC['Region_RC']==99].iloc[0].Gender_RC\n",
    "    children = complete_RC[complete_RC['Region_RC']==99].iloc[0].Children\n",
    "    cars = complete_RC[complete_RC['Region_RC']==99].iloc[0].Cars\n",
    "    MS = complete_RC[complete_RC['Region_RC']==99].iloc[0].Marital_Status_RC\n",
    "    home = complete_RC[complete_RC['Region_RC']==99].iloc[0].Home_Owner_RC\n",
    "    CD = complete_RC[complete_RC['Region_RC']==99].iloc[0].Commute_Distance_RC\n",
    "    predicted.__iadd__(model.predict([[income,age,occupation,education,gender,children,cars,MS,home,CD]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    #print('pred loc',predicted[i])\n",
    "    print(\"predicted\",predicted)\n",
    "    #set_region_null.at.index[i],'Region_RC' = predicted[i]\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    print(\"i\",i)\n",
    "    complete_RC.at[complete_RC[complete_RC['Region_RC']==99].index[0],'Region_RC']= predicted[i] # 0:Europe, 1:NA,2:Pacific\n",
    "    #bikes.at[bikes[bikes['Region_RC'] == 99].index[0],'Region_RC'] = mode_region\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predicted\n",
    "len(complete_RC[complete_RC['Region_RC']==99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Income, Children, Cars, Region, Age, Marital_Status_RC, Gender_RC, Education_RC, Occupation_RC, Home_Owner_RC, Commute_Distance_RC, Purchased Bike, Region_RC]\n",
       "Index: []"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after\n",
    "complete_RC[complete_RC['Region_RC']==99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age\n",
    "Split the null and not null values\n",
    "\n",
    "variables (Home Owner, Gender, Marital Status, Cars, Education,Children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Income, Children, Cars, Region, Age, Marital_Status_RC, Gender_RC, Education_RC, Occupation_RC, Home_Owner_RC, Commute_Distance_RC, Purchased Bike, Region_RC]\n",
       "Index: []"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_RC[complete_RC['Age'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 8\n"
     ]
    }
   ],
   "source": [
    "complete_RC_isnull = complete_RC[complete_RC['Purchased Bike'].isnull()]\n",
    "complete_RC_notnull = complete_RC[complete_RC['Purchased Bike'].notnull()]\n",
    "set_age_notnull = complete_RC_notnull[complete_RC_notnull['Age'].notnull()]\n",
    "set_age_null = complete_RC_notnull[complete_RC_notnull['Age'].isnull()]\n",
    "print(len(set_age_notnull),len(set_age_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Europe', 'Pacific', 'Unknown', 'North America'], dtype=object)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_age_notnull['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet 591 testSet 148\n"
     ]
    }
   ],
   "source": [
    "set_age_null = set_age_null[set_age_null['Income'].notnull()]\n",
    "set_age_notnull = set_age_notnull[set_age_notnull['Income'].notnull()]\n",
    "set_age_null = set_age_null[set_age_null['Age'].notnull()]\n",
    "set_age_notnull = set_age_notnull[set_age_notnull['Age'].notnull()]\n",
    "\n",
    "set_age_null['Region_RC'] = le.fit_transform(set_age_null['Region'])\n",
    "set_age_notnull['Region_RC'] = le.fit_transform(set_age_notnull['Region'])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainingSet, testSet = train_test_split(set_age_notnull, test_size=0.2)\n",
    "print('trainingSet',len(trainingSet),'testSet',len(testSet))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(zip(trainingSet['Income'],trainingSet['Occupation_RC'],trainingSet['Region_RC'],trainingSet['Education_RC'],trainingSet['Gender_RC'],trainingSet['Children'],trainingSet['Cars'],trainingSet['Marital_Status_RC'],trainingSet['Home_Owner_RC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0945945945945946\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=2) #2 has the highest accuracy , determined by the next code block\n",
    "model.fit(features,trainingSet['Age'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    region = testSet.iloc[i].Region_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Age, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy provided is only ~12% but thus might be due to the ages beinig too specific. lets recast them into categories of 5 years and see where that leads to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show minimal value\n",
    "set_age_notnull['Age'].unique().min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show maximum value\n",
    "set_age_notnull['Age'].unique().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat']=set_age_notnull['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([25,26,27,28,29], '25-29')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([30,31,32,33,34], '30-34')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([35,36,37,38,39], '35-39')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([40,41,42,43,44], '40-44')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([45,46,47,48,49], '45-49')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([50,51,52,53,54], '50-54')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([55,56,57,58,59], '55-59')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([60,61,62,63,64], '60-64')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([65,66,67,68,69], '65-69')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([70,71,72,73,74], '70-74')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([75,76,77,78,79], '75-79')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([80,81,82,83,84], '80-84')\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].replace([85,86,87,88,89], '85-89')\n",
    "\n",
    "set_age_notnull['Age_Cat'] = set_age_notnull['Age_Cat'].map( {'25-29': 25, '30-34': 30, '35-39': 35, '40-44': 40, '45-49': 45, '50-54': 50,'55-59':55,'60-64':60,'65-69':65,'70-74':70,'75-79':75,'80-84':80,'85-89':85} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([40, 60, 35, 50, 30, 55, 45, 25, 65, 70, 75, 85, 80])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_age_notnull['Age_Cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet 591 testSet 148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainingSet, testSet = train_test_split(set_age_notnull, test_size=0.2)\n",
    "print('trainingSet',len(trainingSet),'testSet',len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([65, 25, 45, 35, 40, 55, 30, 50, 75, 60, 70, 85])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet['Age_Cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([35, 65, 30, 60, 40, 25, 45, 55, 50, 70, 80])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSet['Age_Cat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet 12 testSet 11\n"
     ]
    }
   ],
   "source": [
    "print('trainingSet',len(trainingSet['Age_Cat'].unique()),'testSet',len(testSet['Age_Cat'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.12162162162162163\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "model = KNeighborsClassifier(n_neighbors=2) #2 has the highest accuracy , determined by the next code block\n",
    "model.fit(features,trainingSet['Age_Cat'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    region = testSet.iloc[i].Region_RC\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Age_Cat, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've jumped to ~14% , what happens of we increase the ranges of the ages?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat2']=set_age_notnull['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([25,26,27,28,29,30,31,32,33,34], '25-34')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([35,36,37,38,39,40,41,42,43,44], '35-44')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([45,46,47,48,49,50,51,52,53,54], '45-54')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([55,56,57,58,59,60,61,62,63,64], '55-64')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([65,66,67,68,69,70,71,72,73,74], '65-74')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([75,76,77,78,79,80,81,82,83,84], '75-84')\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].replace([85,86,87,88,89], '85-89')\n",
    "\n",
    "set_age_notnull['Age_Cat2'] = set_age_notnull['Age_Cat2'].map( {'25-34': 34, '35-44': 44, '45-54': 54, '55-64': 64, '65-74': 74, '75-84': 84,'85-89':89} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 64, 54, 34, 74, 84, 89])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_age_notnull['Age_Cat2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet 591 testSet 148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainingSet, testSet = train_test_split(set_age_notnull, test_size=0.2)\n",
    "print('trainingSet',len(trainingSet),'testSet',len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1 0.22297297297297297\n",
      "Accuracy: 2 0.33783783783783783\n",
      "Accuracy: 3 0.27702702702702703\n",
      "Accuracy: 4 0.2635135135135135\n",
      "Accuracy: 5 0.2635135135135135\n",
      "Accuracy: 6 0.23648648648648649\n",
      "Accuracy: 7 0.25675675675675674\n",
      "Accuracy: 8 0.25\n",
      "Accuracy: 9 0.2702702702702703\n",
      "Accuracy: 10 0.28378378378378377\n",
      "Accuracy: 11 0.3310810810810811\n",
      "Accuracy: 12 0.28378378378378377\n",
      "Accuracy: 13 0.2972972972972973\n",
      "Accuracy: 14 0.2635135135135135\n",
      "Accuracy: 15 0.2635135135135135\n",
      "Accuracy: 16 0.2702702702702703\n",
      "Accuracy: 17 0.2635135135135135\n",
      "Accuracy: 18 0.25\n",
      "Accuracy: 19 0.25675675675675674\n",
      "Accuracy: 20 0.2635135135135135\n",
      "Accuracy: 21 0.24324324324324326\n",
      "Accuracy: 22 0.24324324324324326\n",
      "Accuracy: 23 0.23648648648648649\n",
      "Accuracy: 24 0.25\n",
      "Accuracy: 25 0.25\n",
      "Accuracy: 26 0.22972972972972974\n",
      "Accuracy: 27 0.22297297297297297\n",
      "Accuracy: 28 0.23648648648648649\n",
      "Accuracy: 29 0.22297297297297297\n",
      "Accuracy: 30 0.21621621621621623\n",
      "Accuracy: 31 0.24324324324324326\n",
      "Accuracy: 32 0.23648648648648649\n",
      "Accuracy: 33 0.2635135135135135\n",
      "Accuracy: 34 0.2702702702702703\n",
      "Accuracy: 35 0.25\n",
      "Accuracy: 36 0.25\n",
      "Accuracy: 37 0.23648648648648649\n",
      "Accuracy: 38 0.24324324324324326\n",
      "Accuracy: 39 0.24324324324324326\n",
      "Accuracy: 40 0.2702702702702703\n",
      "Accuracy: 41 0.2635135135135135\n",
      "Accuracy: 42 0.2635135135135135\n",
      "Accuracy: 43 0.27702702702702703\n",
      "Accuracy: 44 0.2702702702702703\n",
      "Accuracy: 45 0.25675675675675674\n",
      "Accuracy: 46 0.25\n",
      "Accuracy: 47 0.27702702702702703\n",
      "Accuracy: 48 0.2905405405405405\n",
      "Accuracy: 49 0.27702702702702703\n",
      "Accuracy: 50 0.2905405405405405\n",
      "Accuracy: 51 0.28378378378378377\n",
      "Accuracy: 52 0.27702702702702703\n",
      "Accuracy: 53 0.2702702702702703\n",
      "Accuracy: 54 0.28378378378378377\n",
      "Accuracy: 55 0.2905405405405405\n",
      "Accuracy: 56 0.2702702702702703\n",
      "Accuracy: 57 0.2905405405405405\n",
      "Accuracy: 58 0.2905405405405405\n",
      "Accuracy: 59 0.28378378378378377\n",
      "Accuracy: 60 0.27702702702702703\n",
      "Accuracy: 61 0.2905405405405405\n",
      "Accuracy: 62 0.27702702702702703\n",
      "Accuracy: 63 0.27702702702702703\n",
      "Accuracy: 64 0.27702702702702703\n",
      "Accuracy: 65 0.2905405405405405\n",
      "Accuracy: 66 0.2905405405405405\n",
      "Accuracy: 67 0.2635135135135135\n",
      "Accuracy: 68 0.2905405405405405\n",
      "Accuracy: 69 0.2702702702702703\n",
      "Accuracy: 70 0.2905405405405405\n",
      "Accuracy: 71 0.28378378378378377\n",
      "Accuracy: 72 0.2972972972972973\n",
      "Accuracy: 73 0.3108108108108108\n",
      "Accuracy: 74 0.2972972972972973\n",
      "Accuracy: 75 0.2972972972972973\n",
      "Accuracy: 76 0.28378378378378377\n",
      "Accuracy: 77 0.27702702702702703\n",
      "Accuracy: 78 0.28378378378378377\n",
      "Accuracy: 79 0.2905405405405405\n",
      "Accuracy: 80 0.2972972972972973\n",
      "Accuracy: 81 0.3108108108108108\n",
      "Accuracy: 82 0.31756756756756754\n",
      "Accuracy: 83 0.30405405405405406\n",
      "Accuracy: 84 0.31756756756756754\n",
      "Accuracy: 85 0.3108108108108108\n",
      "Accuracy: 86 0.3108108108108108\n",
      "Accuracy: 87 0.32432432432432434\n",
      "Accuracy: 88 0.32432432432432434\n",
      "Accuracy: 89 0.3108108108108108\n",
      "Accuracy: 90 0.3108108108108108\n",
      "Accuracy: 91 0.32432432432432434\n",
      "Accuracy: 92 0.32432432432432434\n",
      "Accuracy: 93 0.3310810810810811\n",
      "Accuracy: 94 0.32432432432432434\n",
      "Accuracy: 95 0.3310810810810811\n",
      "Accuracy: 96 0.32432432432432434\n",
      "Accuracy: 97 0.3310810810810811\n",
      "Accuracy: 98 0.3310810810810811\n",
      "Accuracy: 99 0.3310810810810811\n",
      "Accuracy: 100 0.32432432432432434\n",
      "Accuracy: 101 0.3310810810810811\n",
      "Accuracy: 102 0.3310810810810811\n",
      "Accuracy: 103 0.32432432432432434\n",
      "Accuracy: 104 0.32432432432432434\n",
      "Accuracy: 105 0.31756756756756754\n",
      "Accuracy: 106 0.32432432432432434\n",
      "Accuracy: 107 0.32432432432432434\n",
      "Accuracy: 108 0.31756756756756754\n",
      "Accuracy: 109 0.3108108108108108\n",
      "Accuracy: 110 0.3108108108108108\n",
      "Accuracy: 111 0.3108108108108108\n",
      "Accuracy: 112 0.3108108108108108\n",
      "Accuracy: 113 0.3108108108108108\n",
      "Accuracy: 114 0.3108108108108108\n",
      "Accuracy: 115 0.31756756756756754\n",
      "Accuracy: 116 0.31756756756756754\n",
      "Accuracy: 117 0.31756756756756754\n",
      "Accuracy: 118 0.31756756756756754\n",
      "Accuracy: 119 0.31756756756756754\n",
      "Accuracy: 120 0.31756756756756754\n",
      "Accuracy: 121 0.32432432432432434\n",
      "Accuracy: 122 0.32432432432432434\n",
      "Accuracy: 123 0.32432432432432434\n",
      "Accuracy: 124 0.3310810810810811\n",
      "Accuracy: 125 0.32432432432432434\n",
      "Accuracy: 126 0.3310810810810811\n",
      "Accuracy: 127 0.33783783783783783\n",
      "Accuracy: 128 0.34459459459459457\n",
      "Accuracy: 129 0.34459459459459457\n",
      "Accuracy: 130 0.33783783783783783\n",
      "Accuracy: 131 0.34459459459459457\n",
      "Accuracy: 132 0.3310810810810811\n",
      "Accuracy: 133 0.3310810810810811\n",
      "Accuracy: 134 0.33783783783783783\n",
      "Accuracy: 135 0.33783783783783783\n",
      "Accuracy: 136 0.33783783783783783\n",
      "Accuracy: 137 0.34459459459459457\n",
      "Accuracy: 138 0.34459459459459457\n",
      "Accuracy: 139 0.34459459459459457\n",
      "Accuracy: 140 0.34459459459459457\n",
      "Accuracy: 141 0.33783783783783783\n",
      "Accuracy: 142 0.33783783783783783\n",
      "Accuracy: 143 0.34459459459459457\n",
      "Accuracy: 144 0.33783783783783783\n",
      "Accuracy: 145 0.34459459459459457\n",
      "Accuracy: 146 0.34459459459459457\n",
      "Accuracy: 147 0.33783783783783783\n",
      "Accuracy: 148 0.3310810810810811\n",
      "Accuracy: 149 0.3310810810810811\n",
      "Accuracy: 150 0.33783783783783783\n",
      "Accuracy: 151 0.3310810810810811\n",
      "Accuracy: 152 0.34459459459459457\n",
      "Accuracy: 153 0.34459459459459457\n",
      "Accuracy: 154 0.34459459459459457\n",
      "Accuracy: 155 0.34459459459459457\n",
      "Accuracy: 156 0.34459459459459457\n",
      "Accuracy: 157 0.34459459459459457\n",
      "Accuracy: 158 0.34459459459459457\n",
      "Accuracy: 159 0.34459459459459457\n",
      "Accuracy: 160 0.34459459459459457\n",
      "Accuracy: 161 0.34459459459459457\n",
      "Accuracy: 162 0.34459459459459457\n",
      "Accuracy: 163 0.34459459459459457\n",
      "Accuracy: 164 0.34459459459459457\n",
      "Accuracy: 165 0.34459459459459457\n",
      "Accuracy: 166 0.34459459459459457\n",
      "Accuracy: 167 0.34459459459459457\n",
      "Accuracy: 168 0.34459459459459457\n",
      "Accuracy: 169 0.34459459459459457\n",
      "Accuracy: 170 0.34459459459459457\n",
      "Accuracy: 171 0.34459459459459457\n",
      "Accuracy: 172 0.34459459459459457\n",
      "Accuracy: 173 0.34459459459459457\n",
      "Accuracy: 174 0.34459459459459457\n",
      "Accuracy: 175 0.34459459459459457\n",
      "Accuracy: 176 0.34459459459459457\n",
      "Accuracy: 177 0.34459459459459457\n",
      "Accuracy: 178 0.34459459459459457\n",
      "Accuracy: 179 0.34459459459459457\n",
      "Accuracy: 180 0.34459459459459457\n",
      "Accuracy: 181 0.34459459459459457\n",
      "Accuracy: 182 0.34459459459459457\n",
      "Accuracy: 183 0.34459459459459457\n",
      "Accuracy: 184 0.34459459459459457\n",
      "Accuracy: 185 0.34459459459459457\n",
      "Accuracy: 186 0.34459459459459457\n",
      "Accuracy: 187 0.34459459459459457\n",
      "Accuracy: 188 0.34459459459459457\n",
      "Accuracy: 189 0.34459459459459457\n",
      "Accuracy: 190 0.34459459459459457\n",
      "Accuracy: 191 0.34459459459459457\n",
      "Accuracy: 192 0.34459459459459457\n",
      "Accuracy: 193 0.34459459459459457\n",
      "Accuracy: 194 0.34459459459459457\n",
      "Accuracy: 195 0.34459459459459457\n",
      "Accuracy: 196 0.34459459459459457\n",
      "Accuracy: 197 0.34459459459459457\n",
      "Accuracy: 198 0.34459459459459457\n",
      "Accuracy: 199 0.34459459459459457\n",
      "Accuracy: 200 0.34459459459459457\n",
      "Accuracy: 201 0.34459459459459457\n",
      "Accuracy: 202 0.34459459459459457\n",
      "Accuracy: 203 0.34459459459459457\n",
      "Accuracy: 204 0.34459459459459457\n",
      "Accuracy: 205 0.34459459459459457\n",
      "Accuracy: 206 0.34459459459459457\n",
      "Accuracy: 207 0.34459459459459457\n",
      "Accuracy: 208 0.34459459459459457\n",
      "Accuracy: 209 0.34459459459459457\n",
      "Accuracy: 210 0.34459459459459457\n",
      "Accuracy: 211 0.34459459459459457\n",
      "Accuracy: 212 0.34459459459459457\n",
      "Accuracy: 213 0.34459459459459457\n",
      "Accuracy: 214 0.34459459459459457\n",
      "Accuracy: 215 0.34459459459459457\n",
      "Accuracy: 216 0.34459459459459457\n",
      "Accuracy: 217 0.34459459459459457\n",
      "Accuracy: 218 0.34459459459459457\n",
      "Accuracy: 219 0.34459459459459457\n",
      "Accuracy: 220 0.34459459459459457\n",
      "Accuracy: 221 0.34459459459459457\n",
      "Accuracy: 222 0.34459459459459457\n",
      "Accuracy: 223 0.34459459459459457\n",
      "Accuracy: 224 0.34459459459459457\n",
      "Accuracy: 225 0.34459459459459457\n",
      "Accuracy: 226 0.34459459459459457\n",
      "Accuracy: 227 0.34459459459459457\n",
      "Accuracy: 228 0.34459459459459457\n",
      "Accuracy: 229 0.34459459459459457\n",
      "Accuracy: 230 0.34459459459459457\n",
      "Accuracy: 231 0.34459459459459457\n",
      "Accuracy: 232 0.34459459459459457\n",
      "Accuracy: 233 0.34459459459459457\n",
      "Accuracy: 234 0.34459459459459457\n",
      "Accuracy: 235 0.34459459459459457\n",
      "Accuracy: 236 0.34459459459459457\n",
      "Accuracy: 237 0.34459459459459457\n",
      "Accuracy: 238 0.34459459459459457\n",
      "Accuracy: 239 0.34459459459459457\n",
      "Accuracy: 240 0.34459459459459457\n",
      "Accuracy: 241 0.34459459459459457\n",
      "Accuracy: 242 0.34459459459459457\n",
      "Accuracy: 243 0.34459459459459457\n",
      "Accuracy: 244 0.34459459459459457\n",
      "Accuracy: 245 0.34459459459459457\n",
      "Accuracy: 246 0.34459459459459457\n",
      "Accuracy: 247 0.34459459459459457\n",
      "Accuracy: 248 0.34459459459459457\n",
      "Accuracy: 249 0.34459459459459457\n",
      "Accuracy: 250 0.34459459459459457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 251 0.34459459459459457\n",
      "Accuracy: 252 0.34459459459459457\n",
      "Accuracy: 253 0.34459459459459457\n",
      "Accuracy: 254 0.34459459459459457\n",
      "Accuracy: 255 0.34459459459459457\n",
      "Accuracy: 256 0.34459459459459457\n",
      "Accuracy: 257 0.34459459459459457\n",
      "Accuracy: 258 0.34459459459459457\n",
      "Accuracy: 259 0.34459459459459457\n",
      "Accuracy: 260 0.34459459459459457\n",
      "Accuracy: 261 0.34459459459459457\n",
      "Accuracy: 262 0.34459459459459457\n",
      "Accuracy: 263 0.34459459459459457\n",
      "Accuracy: 264 0.34459459459459457\n",
      "Accuracy: 265 0.34459459459459457\n",
      "Accuracy: 266 0.34459459459459457\n",
      "Accuracy: 267 0.34459459459459457\n",
      "Accuracy: 268 0.34459459459459457\n",
      "Accuracy: 269 0.34459459459459457\n",
      "Accuracy: 270 0.34459459459459457\n",
      "Accuracy: 271 0.34459459459459457\n",
      "Accuracy: 272 0.34459459459459457\n",
      "Accuracy: 273 0.34459459459459457\n",
      "Accuracy: 274 0.34459459459459457\n",
      "Accuracy: 275 0.34459459459459457\n",
      "Accuracy: 276 0.34459459459459457\n",
      "Accuracy: 277 0.34459459459459457\n",
      "Accuracy: 278 0.34459459459459457\n",
      "Accuracy: 279 0.34459459459459457\n",
      "Accuracy: 280 0.34459459459459457\n",
      "Accuracy: 281 0.34459459459459457\n",
      "Accuracy: 282 0.34459459459459457\n",
      "Accuracy: 283 0.34459459459459457\n",
      "Accuracy: 284 0.34459459459459457\n",
      "Accuracy: 285 0.34459459459459457\n",
      "Accuracy: 286 0.34459459459459457\n",
      "Accuracy: 287 0.34459459459459457\n",
      "Accuracy: 288 0.34459459459459457\n",
      "Accuracy: 289 0.34459459459459457\n",
      "Accuracy: 290 0.34459459459459457\n",
      "Accuracy: 291 0.34459459459459457\n",
      "Accuracy: 292 0.34459459459459457\n",
      "Accuracy: 293 0.34459459459459457\n",
      "Accuracy: 294 0.34459459459459457\n",
      "Accuracy: 295 0.34459459459459457\n",
      "Accuracy: 296 0.34459459459459457\n",
      "Accuracy: 297 0.34459459459459457\n",
      "Accuracy: 298 0.34459459459459457\n",
      "Accuracy: 299 0.34459459459459457\n",
      "Accuracy: 300 0.34459459459459457\n",
      "Accuracy: 301 0.34459459459459457\n",
      "Accuracy: 302 0.34459459459459457\n",
      "Accuracy: 303 0.34459459459459457\n",
      "Accuracy: 304 0.34459459459459457\n",
      "Accuracy: 305 0.34459459459459457\n",
      "Accuracy: 306 0.34459459459459457\n",
      "Accuracy: 307 0.34459459459459457\n",
      "Accuracy: 308 0.34459459459459457\n",
      "Accuracy: 309 0.34459459459459457\n",
      "Accuracy: 310 0.34459459459459457\n",
      "Accuracy: 311 0.34459459459459457\n",
      "Accuracy: 312 0.34459459459459457\n",
      "Accuracy: 313 0.34459459459459457\n",
      "Accuracy: 314 0.34459459459459457\n",
      "Accuracy: 315 0.34459459459459457\n",
      "Accuracy: 316 0.34459459459459457\n",
      "Accuracy: 317 0.34459459459459457\n",
      "Accuracy: 318 0.34459459459459457\n",
      "Accuracy: 319 0.34459459459459457\n",
      "Accuracy: 320 0.34459459459459457\n",
      "Accuracy: 321 0.34459459459459457\n",
      "Accuracy: 322 0.34459459459459457\n",
      "Accuracy: 323 0.34459459459459457\n",
      "Accuracy: 324 0.34459459459459457\n",
      "Accuracy: 325 0.34459459459459457\n",
      "Accuracy: 326 0.34459459459459457\n",
      "Accuracy: 327 0.34459459459459457\n",
      "Accuracy: 328 0.34459459459459457\n",
      "Accuracy: 329 0.34459459459459457\n",
      "Accuracy: 330 0.34459459459459457\n",
      "Accuracy: 331 0.34459459459459457\n",
      "Accuracy: 332 0.34459459459459457\n",
      "Accuracy: 333 0.34459459459459457\n",
      "Accuracy: 334 0.34459459459459457\n",
      "Accuracy: 335 0.34459459459459457\n",
      "Accuracy: 336 0.34459459459459457\n",
      "Accuracy: 337 0.34459459459459457\n",
      "Accuracy: 338 0.34459459459459457\n",
      "Accuracy: 339 0.34459459459459457\n",
      "Accuracy: 340 0.34459459459459457\n",
      "Accuracy: 341 0.34459459459459457\n",
      "Accuracy: 342 0.34459459459459457\n",
      "Accuracy: 343 0.34459459459459457\n",
      "Accuracy: 344 0.34459459459459457\n",
      "Accuracy: 345 0.34459459459459457\n",
      "Accuracy: 346 0.34459459459459457\n",
      "Accuracy: 347 0.34459459459459457\n",
      "Accuracy: 348 0.34459459459459457\n",
      "Accuracy: 349 0.34459459459459457\n",
      "Accuracy: 350 0.34459459459459457\n",
      "Accuracy: 351 0.34459459459459457\n",
      "Accuracy: 352 0.34459459459459457\n",
      "Accuracy: 353 0.34459459459459457\n",
      "Accuracy: 354 0.34459459459459457\n",
      "Accuracy: 355 0.34459459459459457\n",
      "Accuracy: 356 0.34459459459459457\n",
      "Accuracy: 357 0.34459459459459457\n",
      "Accuracy: 358 0.34459459459459457\n",
      "Accuracy: 359 0.34459459459459457\n",
      "Accuracy: 360 0.34459459459459457\n",
      "Accuracy: 361 0.34459459459459457\n",
      "Accuracy: 362 0.34459459459459457\n",
      "Accuracy: 363 0.34459459459459457\n",
      "Accuracy: 364 0.34459459459459457\n",
      "Accuracy: 365 0.34459459459459457\n",
      "Accuracy: 366 0.34459459459459457\n",
      "Accuracy: 367 0.34459459459459457\n",
      "Accuracy: 368 0.34459459459459457\n",
      "Accuracy: 369 0.34459459459459457\n",
      "Accuracy: 370 0.34459459459459457\n",
      "Accuracy: 371 0.34459459459459457\n",
      "Accuracy: 372 0.34459459459459457\n",
      "Accuracy: 373 0.34459459459459457\n",
      "Accuracy: 374 0.34459459459459457\n",
      "Accuracy: 375 0.34459459459459457\n",
      "Accuracy: 376 0.34459459459459457\n",
      "Accuracy: 377 0.34459459459459457\n",
      "Accuracy: 378 0.34459459459459457\n",
      "Accuracy: 379 0.34459459459459457\n",
      "Accuracy: 380 0.34459459459459457\n",
      "Accuracy: 381 0.34459459459459457\n",
      "Accuracy: 382 0.34459459459459457\n",
      "Accuracy: 383 0.34459459459459457\n",
      "Accuracy: 384 0.34459459459459457\n",
      "Accuracy: 385 0.34459459459459457\n",
      "Accuracy: 386 0.34459459459459457\n",
      "Accuracy: 387 0.34459459459459457\n",
      "Accuracy: 388 0.34459459459459457\n",
      "Accuracy: 389 0.34459459459459457\n",
      "Accuracy: 390 0.34459459459459457\n",
      "Accuracy: 391 0.34459459459459457\n",
      "Accuracy: 392 0.34459459459459457\n",
      "Accuracy: 393 0.34459459459459457\n",
      "Accuracy: 394 0.34459459459459457\n",
      "Accuracy: 395 0.34459459459459457\n",
      "Accuracy: 396 0.34459459459459457\n",
      "Accuracy: 397 0.34459459459459457\n",
      "Accuracy: 398 0.34459459459459457\n",
      "Accuracy: 399 0.34459459459459457\n",
      "Accuracy: 400 0.34459459459459457\n",
      "Accuracy: 401 0.34459459459459457\n",
      "Accuracy: 402 0.34459459459459457\n",
      "Accuracy: 403 0.34459459459459457\n",
      "Accuracy: 404 0.34459459459459457\n",
      "Accuracy: 405 0.34459459459459457\n",
      "Accuracy: 406 0.34459459459459457\n",
      "Accuracy: 407 0.34459459459459457\n",
      "Accuracy: 408 0.34459459459459457\n",
      "Accuracy: 409 0.34459459459459457\n",
      "Accuracy: 410 0.34459459459459457\n",
      "Accuracy: 411 0.34459459459459457\n",
      "Accuracy: 412 0.34459459459459457\n",
      "Accuracy: 413 0.34459459459459457\n",
      "Accuracy: 414 0.34459459459459457\n",
      "Accuracy: 415 0.34459459459459457\n",
      "Accuracy: 416 0.34459459459459457\n",
      "Accuracy: 417 0.34459459459459457\n",
      "Accuracy: 418 0.34459459459459457\n",
      "Accuracy: 419 0.34459459459459457\n",
      "Accuracy: 420 0.34459459459459457\n",
      "Accuracy: 421 0.34459459459459457\n",
      "Accuracy: 422 0.34459459459459457\n",
      "Accuracy: 423 0.34459459459459457\n",
      "Accuracy: 424 0.34459459459459457\n",
      "Accuracy: 425 0.34459459459459457\n",
      "Accuracy: 426 0.34459459459459457\n",
      "Accuracy: 427 0.34459459459459457\n",
      "Accuracy: 428 0.34459459459459457\n",
      "Accuracy: 429 0.34459459459459457\n",
      "Accuracy: 430 0.34459459459459457\n",
      "Accuracy: 431 0.34459459459459457\n",
      "Accuracy: 432 0.34459459459459457\n",
      "Accuracy: 433 0.34459459459459457\n",
      "Accuracy: 434 0.34459459459459457\n",
      "Accuracy: 435 0.34459459459459457\n",
      "Accuracy: 436 0.34459459459459457\n",
      "Accuracy: 437 0.34459459459459457\n",
      "Accuracy: 438 0.34459459459459457\n",
      "Accuracy: 439 0.34459459459459457\n",
      "Accuracy: 440 0.34459459459459457\n",
      "Accuracy: 441 0.34459459459459457\n",
      "Accuracy: 442 0.34459459459459457\n",
      "Accuracy: 443 0.34459459459459457\n",
      "Accuracy: 444 0.34459459459459457\n",
      "Accuracy: 445 0.34459459459459457\n",
      "Accuracy: 446 0.34459459459459457\n",
      "Accuracy: 447 0.34459459459459457\n",
      "Accuracy: 448 0.34459459459459457\n",
      "Accuracy: 449 0.34459459459459457\n",
      "Accuracy: 450 0.34459459459459457\n",
      "Accuracy: 451 0.34459459459459457\n",
      "Accuracy: 452 0.34459459459459457\n",
      "Accuracy: 453 0.34459459459459457\n",
      "Accuracy: 454 0.34459459459459457\n",
      "Accuracy: 455 0.34459459459459457\n",
      "Accuracy: 456 0.34459459459459457\n",
      "Accuracy: 457 0.34459459459459457\n",
      "Accuracy: 458 0.34459459459459457\n",
      "Accuracy: 459 0.34459459459459457\n",
      "Accuracy: 460 0.34459459459459457\n",
      "Accuracy: 461 0.34459459459459457\n",
      "Accuracy: 462 0.34459459459459457\n",
      "Accuracy: 463 0.34459459459459457\n",
      "Accuracy: 464 0.34459459459459457\n",
      "Accuracy: 465 0.34459459459459457\n",
      "Accuracy: 466 0.34459459459459457\n",
      "Accuracy: 467 0.34459459459459457\n",
      "Accuracy: 468 0.34459459459459457\n",
      "Accuracy: 469 0.34459459459459457\n",
      "Accuracy: 470 0.34459459459459457\n",
      "Accuracy: 471 0.34459459459459457\n",
      "Accuracy: 472 0.34459459459459457\n",
      "Accuracy: 473 0.34459459459459457\n",
      "Accuracy: 474 0.34459459459459457\n",
      "Accuracy: 475 0.34459459459459457\n",
      "Accuracy: 476 0.34459459459459457\n",
      "Accuracy: 477 0.34459459459459457\n",
      "Accuracy: 478 0.34459459459459457\n",
      "Accuracy: 479 0.34459459459459457\n",
      "Accuracy: 480 0.34459459459459457\n",
      "Accuracy: 481 0.34459459459459457\n",
      "Accuracy: 482 0.34459459459459457\n",
      "Accuracy: 483 0.34459459459459457\n",
      "Accuracy: 484 0.34459459459459457\n",
      "Accuracy: 485 0.34459459459459457\n",
      "Accuracy: 486 0.34459459459459457\n",
      "Accuracy: 487 0.34459459459459457\n",
      "Accuracy: 488 0.34459459459459457\n",
      "Accuracy: 489 0.34459459459459457\n",
      "Accuracy: 490 0.34459459459459457\n",
      "Accuracy: 491 0.34459459459459457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 492 0.34459459459459457\n",
      "Accuracy: 493 0.34459459459459457\n",
      "Accuracy: 494 0.34459459459459457\n",
      "Accuracy: 495 0.34459459459459457\n",
      "Accuracy: 496 0.34459459459459457\n",
      "Accuracy: 497 0.34459459459459457\n",
      "Accuracy: 498 0.34459459459459457\n",
      "Accuracy: 499 0.34459459459459457\n",
      "Accuracy: 500 0.34459459459459457\n",
      "Accuracy: 501 0.34459459459459457\n",
      "Accuracy: 502 0.34459459459459457\n",
      "Accuracy: 503 0.34459459459459457\n",
      "Accuracy: 504 0.34459459459459457\n",
      "Accuracy: 505 0.34459459459459457\n",
      "Accuracy: 506 0.34459459459459457\n",
      "Accuracy: 507 0.34459459459459457\n",
      "Accuracy: 508 0.34459459459459457\n",
      "Accuracy: 509 0.34459459459459457\n",
      "Accuracy: 510 0.34459459459459457\n",
      "Accuracy: 511 0.34459459459459457\n",
      "Accuracy: 512 0.34459459459459457\n",
      "Accuracy: 513 0.34459459459459457\n",
      "Accuracy: 514 0.34459459459459457\n",
      "Accuracy: 515 0.34459459459459457\n",
      "Accuracy: 516 0.34459459459459457\n",
      "Accuracy: 517 0.34459459459459457\n",
      "Accuracy: 518 0.34459459459459457\n",
      "Accuracy: 519 0.34459459459459457\n",
      "Accuracy: 520 0.34459459459459457\n",
      "Accuracy: 521 0.34459459459459457\n",
      "Accuracy: 522 0.34459459459459457\n",
      "Accuracy: 523 0.34459459459459457\n",
      "Accuracy: 524 0.34459459459459457\n",
      "Accuracy: 525 0.34459459459459457\n",
      "Accuracy: 526 0.34459459459459457\n",
      "Accuracy: 527 0.34459459459459457\n",
      "Accuracy: 528 0.34459459459459457\n",
      "Accuracy: 529 0.34459459459459457\n",
      "Accuracy: 530 0.34459459459459457\n",
      "Accuracy: 531 0.34459459459459457\n",
      "Accuracy: 532 0.34459459459459457\n",
      "Accuracy: 533 0.34459459459459457\n",
      "Accuracy: 534 0.34459459459459457\n",
      "Accuracy: 535 0.34459459459459457\n",
      "Accuracy: 536 0.34459459459459457\n",
      "Accuracy: 537 0.34459459459459457\n",
      "Accuracy: 538 0.34459459459459457\n",
      "Accuracy: 539 0.34459459459459457\n",
      "Accuracy: 540 0.34459459459459457\n",
      "Accuracy: 541 0.34459459459459457\n",
      "Accuracy: 542 0.34459459459459457\n",
      "Accuracy: 543 0.34459459459459457\n",
      "Accuracy: 544 0.34459459459459457\n",
      "Accuracy: 545 0.34459459459459457\n",
      "Accuracy: 546 0.34459459459459457\n",
      "Accuracy: 547 0.34459459459459457\n",
      "Accuracy: 548 0.34459459459459457\n",
      "Accuracy: 549 0.34459459459459457\n",
      "Accuracy: 550 0.34459459459459457\n",
      "Accuracy: 551 0.34459459459459457\n",
      "Accuracy: 552 0.34459459459459457\n",
      "Accuracy: 553 0.34459459459459457\n",
      "Accuracy: 554 0.34459459459459457\n",
      "Accuracy: 555 0.34459459459459457\n",
      "Accuracy: 556 0.34459459459459457\n",
      "Accuracy: 557 0.34459459459459457\n",
      "Accuracy: 558 0.34459459459459457\n",
      "Accuracy: 559 0.34459459459459457\n",
      "Accuracy: 560 0.34459459459459457\n",
      "Accuracy: 561 0.34459459459459457\n",
      "Accuracy: 562 0.34459459459459457\n",
      "Accuracy: 563 0.34459459459459457\n",
      "Accuracy: 564 0.34459459459459457\n",
      "Accuracy: 565 0.34459459459459457\n",
      "Accuracy: 566 0.34459459459459457\n",
      "Accuracy: 567 0.34459459459459457\n",
      "Accuracy: 568 0.34459459459459457\n",
      "Accuracy: 569 0.34459459459459457\n",
      "Accuracy: 570 0.34459459459459457\n",
      "Accuracy: 571 0.34459459459459457\n",
      "Accuracy: 572 0.34459459459459457\n",
      "Accuracy: 573 0.34459459459459457\n",
      "Accuracy: 574 0.34459459459459457\n",
      "Accuracy: 575 0.34459459459459457\n",
      "Accuracy: 576 0.34459459459459457\n",
      "Accuracy: 577 0.34459459459459457\n",
      "Accuracy: 578 0.34459459459459457\n",
      "Accuracy: 579 0.34459459459459457\n",
      "Accuracy: 580 0.34459459459459457\n",
      "Accuracy: 581 0.34459459459459457\n",
      "Accuracy: 582 0.34459459459459457\n",
      "Accuracy: 583 0.34459459459459457\n",
      "Accuracy: 584 0.34459459459459457\n",
      "Accuracy: 585 0.34459459459459457\n",
      "Accuracy: 586 0.34459459459459457\n",
      "Accuracy: 587 0.34459459459459457\n",
      "Accuracy: 588 0.34459459459459457\n",
      "Accuracy: 589 0.34459459459459457\n",
      "Accuracy: 590 0.34459459459459457\n",
      "Accuracy: 591 0.34459459459459457\n",
      "max 127\n",
      "max_val 0.34459459459459457\n"
     ]
    }
   ],
   "source": [
    "Acc = []\n",
    "for x in range(len(trainingSet)):\n",
    "    model = KNeighborsClassifier(n_neighbors=x+1)\n",
    "    model.fit(features,trainingSet['Age_Cat2'])\n",
    "    \n",
    "    predicted = []\n",
    "    for i in range(len(testSet)):\n",
    "        income = testSet.iloc[i].Income\n",
    "        region = testSet.iloc[i].Region_RC\n",
    "        occupation = testSet.iloc[i].Occupation_RC\n",
    "        education = testSet.iloc[i].Education_RC\n",
    "        gender = testSet.iloc[i].Gender_RC\n",
    "        children = testSet.iloc[i].Children\n",
    "        cars = testSet.iloc[i].Cars\n",
    "        MS = testSet.iloc[i].Marital_Status_RC\n",
    "        home = testSet.iloc[i].Home_Owner_RC\n",
    "        predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    print(\"Accuracy:\",x+1,metrics.accuracy_score(testSet.Age_Cat2, predicted))\n",
    "    Acc.append(metrics.accuracy_score(testSet.Age_Cat2, predicted))\n",
    "max_value = max(Acc)\n",
    "max_index = Acc.index(max_value)\n",
    "print('max',max_index)\n",
    "print('max_val',max_value)\n",
    "if Acc.index(max_value) == 0: #Crossvalidation is prefered so we're excluding the 1 neighbour value if it's the highest\n",
    "    Acc.remove(Acc[0])\n",
    "    max_value = max(Acc)\n",
    "    max_index = Acc.index(max_value)\n",
    "    print('max',max_index)\n",
    "    print('max_val',max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.22297297297297297,\n",
       " 0.33783783783783783,\n",
       " 0.27702702702702703,\n",
       " 0.2635135135135135,\n",
       " 0.2635135135135135,\n",
       " 0.23648648648648649,\n",
       " 0.25675675675675674,\n",
       " 0.25,\n",
       " 0.2702702702702703,\n",
       " 0.28378378378378377,\n",
       " 0.3310810810810811,\n",
       " 0.28378378378378377,\n",
       " 0.2972972972972973,\n",
       " 0.2635135135135135,\n",
       " 0.2635135135135135,\n",
       " 0.2702702702702703,\n",
       " 0.2635135135135135,\n",
       " 0.25,\n",
       " 0.25675675675675674,\n",
       " 0.2635135135135135,\n",
       " 0.24324324324324326,\n",
       " 0.24324324324324326,\n",
       " 0.23648648648648649,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.22972972972972974,\n",
       " 0.22297297297297297,\n",
       " 0.23648648648648649,\n",
       " 0.22297297297297297,\n",
       " 0.21621621621621623,\n",
       " 0.24324324324324326,\n",
       " 0.23648648648648649,\n",
       " 0.2635135135135135,\n",
       " 0.2702702702702703,\n",
       " 0.25,\n",
       " 0.25,\n",
       " 0.23648648648648649,\n",
       " 0.24324324324324326,\n",
       " 0.24324324324324326,\n",
       " 0.2702702702702703,\n",
       " 0.2635135135135135,\n",
       " 0.2635135135135135,\n",
       " 0.27702702702702703,\n",
       " 0.2702702702702703,\n",
       " 0.25675675675675674,\n",
       " 0.25,\n",
       " 0.27702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.27702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.28378378378378377,\n",
       " 0.27702702702702703,\n",
       " 0.2702702702702703,\n",
       " 0.28378378378378377,\n",
       " 0.2905405405405405,\n",
       " 0.2702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.2905405405405405,\n",
       " 0.28378378378378377,\n",
       " 0.27702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.27702702702702703,\n",
       " 0.27702702702702703,\n",
       " 0.27702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.2905405405405405,\n",
       " 0.2635135135135135,\n",
       " 0.2905405405405405,\n",
       " 0.2702702702702703,\n",
       " 0.2905405405405405,\n",
       " 0.28378378378378377,\n",
       " 0.2972972972972973,\n",
       " 0.3108108108108108,\n",
       " 0.2972972972972973,\n",
       " 0.2972972972972973,\n",
       " 0.28378378378378377,\n",
       " 0.27702702702702703,\n",
       " 0.28378378378378377,\n",
       " 0.2905405405405405,\n",
       " 0.2972972972972973,\n",
       " 0.3108108108108108,\n",
       " 0.31756756756756754,\n",
       " 0.30405405405405406,\n",
       " 0.31756756756756754,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.3310810810810811,\n",
       " 0.3310810810810811,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.3310810810810811,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.31756756756756754,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.31756756756756754,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.3108108108108108,\n",
       " 0.31756756756756754,\n",
       " 0.31756756756756754,\n",
       " 0.31756756756756754,\n",
       " 0.31756756756756754,\n",
       " 0.31756756756756754,\n",
       " 0.31756756756756754,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.32432432432432434,\n",
       " 0.3310810810810811,\n",
       " 0.33783783783783783,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.33783783783783783,\n",
       " 0.34459459459459457,\n",
       " 0.3310810810810811,\n",
       " 0.3310810810810811,\n",
       " 0.33783783783783783,\n",
       " 0.33783783783783783,\n",
       " 0.33783783783783783,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.33783783783783783,\n",
       " 0.33783783783783783,\n",
       " 0.34459459459459457,\n",
       " 0.33783783783783783,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.33783783783783783,\n",
       " 0.3310810810810811,\n",
       " 0.3310810810810811,\n",
       " 0.33783783783783783,\n",
       " 0.3310810810810811,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457,\n",
       " 0.34459459459459457]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34459459459459457\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=max_index+1)\n",
    "model.fit(features,trainingSet['Age_Cat2'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    region = testSet.iloc[i].Region_RC\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Age_Cat2, predicted))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we've jumped to ~35%. let's try 1 more \"new category\" cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat3']=set_age_notnull['Age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Age_Cat3'] = set_age_notnull['Age_Cat3'].replace([25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44], '25-44')\n",
    "set_age_notnull['Age_Cat3'] = set_age_notnull['Age_Cat3'].replace([45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64], '45-64')\n",
    "set_age_notnull['Age_Cat3'] = set_age_notnull['Age_Cat3'].replace([65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84], '65-84')\n",
    "set_age_notnull['Age_Cat3'] = set_age_notnull['Age_Cat3'].replace([85,86,87,88,89], '85-89')\n",
    "\n",
    "set_age_notnull['Age_Cat3'] = set_age_notnull['Age_Cat3'].map( {'25-44': 44, '45-64': 64, '65-84': 84,'85-89':89} ).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainingSet 591 testSet 148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "trainingSet, testSet = train_test_split(set_age_notnull, test_size=0.2)\n",
    "print('trainingSet',len(trainingSet),'testSet',len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1 0.4391891891891892\n",
      "Accuracy: 2 0.47297297297297297\n",
      "Accuracy: 3 0.4797297297297297\n",
      "Accuracy: 4 0.4864864864864865\n",
      "Accuracy: 5 0.527027027027027\n",
      "Accuracy: 6 0.4594594594594595\n",
      "Accuracy: 7 0.5405405405405406\n",
      "Accuracy: 8 0.49324324324324326\n",
      "Accuracy: 9 0.5067567567567568\n",
      "Accuracy: 10 0.5\n",
      "Accuracy: 11 0.5067567567567568\n",
      "Accuracy: 12 0.47297297297297297\n",
      "Accuracy: 13 0.5\n",
      "Accuracy: 14 0.4797297297297297\n",
      "Accuracy: 15 0.5135135135135135\n",
      "Accuracy: 16 0.5\n",
      "Accuracy: 17 0.5135135135135135\n",
      "Accuracy: 18 0.4797297297297297\n",
      "Accuracy: 19 0.4864864864864865\n",
      "Accuracy: 20 0.4864864864864865\n",
      "Accuracy: 21 0.49324324324324326\n",
      "Accuracy: 22 0.46621621621621623\n",
      "Accuracy: 23 0.4594594594594595\n",
      "Accuracy: 24 0.4391891891891892\n",
      "Accuracy: 25 0.4527027027027027\n",
      "Accuracy: 26 0.4594594594594595\n",
      "Accuracy: 27 0.4527027027027027\n",
      "Accuracy: 28 0.4864864864864865\n",
      "Accuracy: 29 0.47297297297297297\n",
      "Accuracy: 30 0.46621621621621623\n",
      "Accuracy: 31 0.4864864864864865\n",
      "Accuracy: 32 0.49324324324324326\n",
      "Accuracy: 33 0.4797297297297297\n",
      "Accuracy: 34 0.5\n",
      "Accuracy: 35 0.5067567567567568\n",
      "Accuracy: 36 0.5202702702702703\n",
      "Accuracy: 37 0.527027027027027\n",
      "Accuracy: 38 0.5202702702702703\n",
      "Accuracy: 39 0.5202702702702703\n",
      "Accuracy: 40 0.5067567567567568\n",
      "Accuracy: 41 0.5202702702702703\n",
      "Accuracy: 42 0.5135135135135135\n",
      "Accuracy: 43 0.5202702702702703\n",
      "Accuracy: 44 0.5337837837837838\n",
      "Accuracy: 45 0.49324324324324326\n",
      "Accuracy: 46 0.4797297297297297\n",
      "Accuracy: 47 0.46621621621621623\n",
      "Accuracy: 48 0.4797297297297297\n",
      "Accuracy: 49 0.4594594594594595\n",
      "Accuracy: 50 0.47297297297297297\n",
      "Accuracy: 51 0.46621621621621623\n",
      "Accuracy: 52 0.49324324324324326\n",
      "Accuracy: 53 0.49324324324324326\n",
      "Accuracy: 54 0.4864864864864865\n",
      "Accuracy: 55 0.49324324324324326\n",
      "Accuracy: 56 0.49324324324324326\n",
      "Accuracy: 57 0.49324324324324326\n",
      "Accuracy: 58 0.4864864864864865\n",
      "Accuracy: 59 0.5067567567567568\n",
      "Accuracy: 60 0.5067567567567568\n",
      "Accuracy: 61 0.5\n",
      "Accuracy: 62 0.5\n",
      "Accuracy: 63 0.5\n",
      "Accuracy: 64 0.5\n",
      "Accuracy: 65 0.5\n",
      "Accuracy: 66 0.5\n",
      "Accuracy: 67 0.49324324324324326\n",
      "Accuracy: 68 0.49324324324324326\n",
      "Accuracy: 69 0.49324324324324326\n",
      "Accuracy: 70 0.49324324324324326\n",
      "Accuracy: 71 0.49324324324324326\n",
      "Accuracy: 72 0.49324324324324326\n",
      "Accuracy: 73 0.49324324324324326\n",
      "Accuracy: 74 0.49324324324324326\n",
      "Accuracy: 75 0.49324324324324326\n",
      "Accuracy: 76 0.49324324324324326\n",
      "Accuracy: 77 0.49324324324324326\n",
      "Accuracy: 78 0.49324324324324326\n",
      "Accuracy: 79 0.49324324324324326\n",
      "Accuracy: 80 0.49324324324324326\n",
      "Accuracy: 81 0.49324324324324326\n",
      "Accuracy: 82 0.49324324324324326\n",
      "Accuracy: 83 0.49324324324324326\n",
      "Accuracy: 84 0.49324324324324326\n",
      "Accuracy: 85 0.49324324324324326\n",
      "Accuracy: 86 0.49324324324324326\n",
      "Accuracy: 87 0.49324324324324326\n",
      "Accuracy: 88 0.49324324324324326\n",
      "Accuracy: 89 0.49324324324324326\n",
      "Accuracy: 90 0.49324324324324326\n",
      "Accuracy: 91 0.49324324324324326\n",
      "Accuracy: 92 0.49324324324324326\n",
      "Accuracy: 93 0.49324324324324326\n",
      "Accuracy: 94 0.49324324324324326\n",
      "Accuracy: 95 0.49324324324324326\n",
      "Accuracy: 96 0.49324324324324326\n",
      "Accuracy: 97 0.49324324324324326\n",
      "Accuracy: 98 0.49324324324324326\n",
      "Accuracy: 99 0.49324324324324326\n",
      "Accuracy: 100 0.49324324324324326\n",
      "Accuracy: 101 0.49324324324324326\n",
      "Accuracy: 102 0.49324324324324326\n",
      "Accuracy: 103 0.49324324324324326\n",
      "Accuracy: 104 0.49324324324324326\n",
      "Accuracy: 105 0.49324324324324326\n",
      "Accuracy: 106 0.49324324324324326\n",
      "Accuracy: 107 0.49324324324324326\n",
      "Accuracy: 108 0.49324324324324326\n",
      "Accuracy: 109 0.49324324324324326\n",
      "Accuracy: 110 0.49324324324324326\n",
      "Accuracy: 111 0.49324324324324326\n",
      "Accuracy: 112 0.49324324324324326\n",
      "Accuracy: 113 0.49324324324324326\n",
      "Accuracy: 114 0.49324324324324326\n",
      "Accuracy: 115 0.49324324324324326\n",
      "Accuracy: 116 0.49324324324324326\n",
      "Accuracy: 117 0.49324324324324326\n",
      "Accuracy: 118 0.49324324324324326\n",
      "Accuracy: 119 0.49324324324324326\n",
      "Accuracy: 120 0.49324324324324326\n",
      "Accuracy: 121 0.49324324324324326\n",
      "Accuracy: 122 0.49324324324324326\n",
      "Accuracy: 123 0.49324324324324326\n",
      "Accuracy: 124 0.49324324324324326\n",
      "Accuracy: 125 0.49324324324324326\n",
      "Accuracy: 126 0.49324324324324326\n",
      "Accuracy: 127 0.49324324324324326\n",
      "Accuracy: 128 0.49324324324324326\n",
      "Accuracy: 129 0.49324324324324326\n",
      "Accuracy: 130 0.49324324324324326\n",
      "Accuracy: 131 0.49324324324324326\n",
      "Accuracy: 132 0.49324324324324326\n",
      "Accuracy: 133 0.49324324324324326\n",
      "Accuracy: 134 0.49324324324324326\n",
      "Accuracy: 135 0.49324324324324326\n",
      "Accuracy: 136 0.49324324324324326\n",
      "Accuracy: 137 0.49324324324324326\n",
      "Accuracy: 138 0.49324324324324326\n",
      "Accuracy: 139 0.49324324324324326\n",
      "Accuracy: 140 0.49324324324324326\n",
      "Accuracy: 141 0.49324324324324326\n",
      "Accuracy: 142 0.49324324324324326\n",
      "Accuracy: 143 0.49324324324324326\n",
      "Accuracy: 144 0.49324324324324326\n",
      "Accuracy: 145 0.49324324324324326\n",
      "Accuracy: 146 0.49324324324324326\n",
      "Accuracy: 147 0.49324324324324326\n",
      "Accuracy: 148 0.49324324324324326\n",
      "Accuracy: 149 0.49324324324324326\n",
      "Accuracy: 150 0.49324324324324326\n",
      "Accuracy: 151 0.49324324324324326\n",
      "Accuracy: 152 0.49324324324324326\n",
      "Accuracy: 153 0.49324324324324326\n",
      "Accuracy: 154 0.49324324324324326\n",
      "Accuracy: 155 0.49324324324324326\n",
      "Accuracy: 156 0.49324324324324326\n",
      "Accuracy: 157 0.49324324324324326\n",
      "Accuracy: 158 0.49324324324324326\n",
      "Accuracy: 159 0.49324324324324326\n",
      "Accuracy: 160 0.49324324324324326\n",
      "Accuracy: 161 0.49324324324324326\n",
      "Accuracy: 162 0.49324324324324326\n",
      "Accuracy: 163 0.49324324324324326\n",
      "Accuracy: 164 0.49324324324324326\n",
      "Accuracy: 165 0.49324324324324326\n",
      "Accuracy: 166 0.49324324324324326\n",
      "Accuracy: 167 0.49324324324324326\n",
      "Accuracy: 168 0.49324324324324326\n",
      "Accuracy: 169 0.49324324324324326\n",
      "Accuracy: 170 0.49324324324324326\n",
      "Accuracy: 171 0.49324324324324326\n",
      "Accuracy: 172 0.49324324324324326\n",
      "Accuracy: 173 0.49324324324324326\n",
      "Accuracy: 174 0.49324324324324326\n",
      "Accuracy: 175 0.49324324324324326\n",
      "Accuracy: 176 0.49324324324324326\n",
      "Accuracy: 177 0.49324324324324326\n",
      "Accuracy: 178 0.49324324324324326\n",
      "Accuracy: 179 0.49324324324324326\n",
      "Accuracy: 180 0.49324324324324326\n",
      "Accuracy: 181 0.49324324324324326\n",
      "Accuracy: 182 0.49324324324324326\n",
      "Accuracy: 183 0.49324324324324326\n",
      "Accuracy: 184 0.49324324324324326\n",
      "Accuracy: 185 0.49324324324324326\n",
      "Accuracy: 186 0.49324324324324326\n",
      "Accuracy: 187 0.49324324324324326\n",
      "Accuracy: 188 0.49324324324324326\n",
      "Accuracy: 189 0.49324324324324326\n",
      "Accuracy: 190 0.49324324324324326\n",
      "Accuracy: 191 0.49324324324324326\n",
      "Accuracy: 192 0.49324324324324326\n",
      "Accuracy: 193 0.49324324324324326\n",
      "Accuracy: 194 0.49324324324324326\n",
      "Accuracy: 195 0.49324324324324326\n",
      "Accuracy: 196 0.49324324324324326\n",
      "Accuracy: 197 0.49324324324324326\n",
      "Accuracy: 198 0.49324324324324326\n",
      "Accuracy: 199 0.49324324324324326\n",
      "Accuracy: 200 0.49324324324324326\n",
      "Accuracy: 201 0.49324324324324326\n",
      "Accuracy: 202 0.49324324324324326\n",
      "Accuracy: 203 0.49324324324324326\n",
      "Accuracy: 204 0.49324324324324326\n",
      "Accuracy: 205 0.49324324324324326\n",
      "Accuracy: 206 0.49324324324324326\n",
      "Accuracy: 207 0.49324324324324326\n",
      "Accuracy: 208 0.49324324324324326\n",
      "Accuracy: 209 0.49324324324324326\n",
      "Accuracy: 210 0.49324324324324326\n",
      "Accuracy: 211 0.49324324324324326\n",
      "Accuracy: 212 0.49324324324324326\n",
      "Accuracy: 213 0.49324324324324326\n",
      "Accuracy: 214 0.49324324324324326\n",
      "Accuracy: 215 0.49324324324324326\n",
      "Accuracy: 216 0.49324324324324326\n",
      "Accuracy: 217 0.49324324324324326\n",
      "Accuracy: 218 0.49324324324324326\n",
      "Accuracy: 219 0.49324324324324326\n",
      "Accuracy: 220 0.49324324324324326\n",
      "Accuracy: 221 0.49324324324324326\n",
      "Accuracy: 222 0.49324324324324326\n",
      "Accuracy: 223 0.49324324324324326\n",
      "Accuracy: 224 0.49324324324324326\n",
      "Accuracy: 225 0.49324324324324326\n",
      "Accuracy: 226 0.49324324324324326\n",
      "Accuracy: 227 0.49324324324324326\n",
      "Accuracy: 228 0.49324324324324326\n",
      "Accuracy: 229 0.49324324324324326\n",
      "Accuracy: 230 0.49324324324324326\n",
      "Accuracy: 231 0.49324324324324326\n",
      "Accuracy: 232 0.49324324324324326\n",
      "Accuracy: 233 0.49324324324324326\n",
      "Accuracy: 234 0.49324324324324326\n",
      "Accuracy: 235 0.49324324324324326\n",
      "Accuracy: 236 0.49324324324324326\n",
      "Accuracy: 237 0.49324324324324326\n",
      "Accuracy: 238 0.49324324324324326\n",
      "Accuracy: 239 0.49324324324324326\n",
      "Accuracy: 240 0.49324324324324326\n",
      "Accuracy: 241 0.49324324324324326\n",
      "Accuracy: 242 0.49324324324324326\n",
      "Accuracy: 243 0.49324324324324326\n",
      "Accuracy: 244 0.49324324324324326\n",
      "Accuracy: 245 0.49324324324324326\n",
      "Accuracy: 246 0.49324324324324326\n",
      "Accuracy: 247 0.49324324324324326\n",
      "Accuracy: 248 0.49324324324324326\n",
      "Accuracy: 249 0.49324324324324326\n",
      "Accuracy: 250 0.49324324324324326\n",
      "Accuracy: 251 0.49324324324324326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 252 0.49324324324324326\n",
      "Accuracy: 253 0.49324324324324326\n",
      "Accuracy: 254 0.49324324324324326\n",
      "Accuracy: 255 0.49324324324324326\n",
      "Accuracy: 256 0.49324324324324326\n",
      "Accuracy: 257 0.49324324324324326\n",
      "Accuracy: 258 0.49324324324324326\n",
      "Accuracy: 259 0.49324324324324326\n",
      "Accuracy: 260 0.49324324324324326\n",
      "Accuracy: 261 0.49324324324324326\n",
      "Accuracy: 262 0.49324324324324326\n",
      "Accuracy: 263 0.49324324324324326\n",
      "Accuracy: 264 0.49324324324324326\n",
      "Accuracy: 265 0.49324324324324326\n",
      "Accuracy: 266 0.49324324324324326\n",
      "Accuracy: 267 0.49324324324324326\n",
      "Accuracy: 268 0.49324324324324326\n",
      "Accuracy: 269 0.49324324324324326\n",
      "Accuracy: 270 0.49324324324324326\n",
      "Accuracy: 271 0.49324324324324326\n",
      "Accuracy: 272 0.49324324324324326\n",
      "Accuracy: 273 0.49324324324324326\n",
      "Accuracy: 274 0.49324324324324326\n",
      "Accuracy: 275 0.49324324324324326\n",
      "Accuracy: 276 0.49324324324324326\n",
      "Accuracy: 277 0.49324324324324326\n",
      "Accuracy: 278 0.49324324324324326\n",
      "Accuracy: 279 0.49324324324324326\n",
      "Accuracy: 280 0.49324324324324326\n",
      "Accuracy: 281 0.49324324324324326\n",
      "Accuracy: 282 0.49324324324324326\n",
      "Accuracy: 283 0.49324324324324326\n",
      "Accuracy: 284 0.49324324324324326\n",
      "Accuracy: 285 0.49324324324324326\n",
      "Accuracy: 286 0.49324324324324326\n",
      "Accuracy: 287 0.49324324324324326\n",
      "Accuracy: 288 0.49324324324324326\n",
      "Accuracy: 289 0.49324324324324326\n",
      "Accuracy: 290 0.49324324324324326\n",
      "Accuracy: 291 0.49324324324324326\n",
      "Accuracy: 292 0.49324324324324326\n",
      "Accuracy: 293 0.49324324324324326\n",
      "Accuracy: 294 0.49324324324324326\n",
      "Accuracy: 295 0.49324324324324326\n",
      "Accuracy: 296 0.49324324324324326\n",
      "Accuracy: 297 0.49324324324324326\n",
      "Accuracy: 298 0.49324324324324326\n",
      "Accuracy: 299 0.49324324324324326\n",
      "Accuracy: 300 0.49324324324324326\n",
      "Accuracy: 301 0.49324324324324326\n",
      "Accuracy: 302 0.49324324324324326\n",
      "Accuracy: 303 0.49324324324324326\n",
      "Accuracy: 304 0.49324324324324326\n",
      "Accuracy: 305 0.49324324324324326\n",
      "Accuracy: 306 0.49324324324324326\n",
      "Accuracy: 307 0.49324324324324326\n",
      "Accuracy: 308 0.49324324324324326\n",
      "Accuracy: 309 0.49324324324324326\n",
      "Accuracy: 310 0.49324324324324326\n",
      "Accuracy: 311 0.49324324324324326\n",
      "Accuracy: 312 0.49324324324324326\n",
      "Accuracy: 313 0.49324324324324326\n",
      "Accuracy: 314 0.49324324324324326\n",
      "Accuracy: 315 0.49324324324324326\n",
      "Accuracy: 316 0.49324324324324326\n",
      "Accuracy: 317 0.49324324324324326\n",
      "Accuracy: 318 0.49324324324324326\n",
      "Accuracy: 319 0.49324324324324326\n",
      "Accuracy: 320 0.49324324324324326\n",
      "Accuracy: 321 0.49324324324324326\n",
      "Accuracy: 322 0.49324324324324326\n",
      "Accuracy: 323 0.49324324324324326\n",
      "Accuracy: 324 0.49324324324324326\n",
      "Accuracy: 325 0.49324324324324326\n",
      "Accuracy: 326 0.49324324324324326\n",
      "Accuracy: 327 0.49324324324324326\n",
      "Accuracy: 328 0.49324324324324326\n",
      "Accuracy: 329 0.49324324324324326\n",
      "Accuracy: 330 0.49324324324324326\n",
      "Accuracy: 331 0.49324324324324326\n",
      "Accuracy: 332 0.49324324324324326\n",
      "Accuracy: 333 0.49324324324324326\n",
      "Accuracy: 334 0.49324324324324326\n",
      "Accuracy: 335 0.49324324324324326\n",
      "Accuracy: 336 0.49324324324324326\n",
      "Accuracy: 337 0.49324324324324326\n",
      "Accuracy: 338 0.49324324324324326\n",
      "Accuracy: 339 0.49324324324324326\n",
      "Accuracy: 340 0.49324324324324326\n",
      "Accuracy: 341 0.49324324324324326\n",
      "Accuracy: 342 0.49324324324324326\n",
      "Accuracy: 343 0.49324324324324326\n",
      "Accuracy: 344 0.49324324324324326\n",
      "Accuracy: 345 0.49324324324324326\n",
      "Accuracy: 346 0.49324324324324326\n",
      "Accuracy: 347 0.49324324324324326\n",
      "Accuracy: 348 0.49324324324324326\n",
      "Accuracy: 349 0.49324324324324326\n",
      "Accuracy: 350 0.49324324324324326\n",
      "Accuracy: 351 0.49324324324324326\n",
      "Accuracy: 352 0.49324324324324326\n",
      "Accuracy: 353 0.49324324324324326\n",
      "Accuracy: 354 0.49324324324324326\n",
      "Accuracy: 355 0.49324324324324326\n",
      "Accuracy: 356 0.49324324324324326\n",
      "Accuracy: 357 0.49324324324324326\n",
      "Accuracy: 358 0.49324324324324326\n",
      "Accuracy: 359 0.49324324324324326\n",
      "Accuracy: 360 0.49324324324324326\n",
      "Accuracy: 361 0.49324324324324326\n",
      "Accuracy: 362 0.49324324324324326\n",
      "Accuracy: 363 0.49324324324324326\n",
      "Accuracy: 364 0.49324324324324326\n",
      "Accuracy: 365 0.49324324324324326\n",
      "Accuracy: 366 0.49324324324324326\n",
      "Accuracy: 367 0.49324324324324326\n",
      "Accuracy: 368 0.49324324324324326\n",
      "Accuracy: 369 0.49324324324324326\n",
      "Accuracy: 370 0.49324324324324326\n",
      "Accuracy: 371 0.49324324324324326\n",
      "Accuracy: 372 0.49324324324324326\n",
      "Accuracy: 373 0.49324324324324326\n",
      "Accuracy: 374 0.49324324324324326\n",
      "Accuracy: 375 0.49324324324324326\n",
      "Accuracy: 376 0.49324324324324326\n",
      "Accuracy: 377 0.49324324324324326\n",
      "Accuracy: 378 0.49324324324324326\n",
      "Accuracy: 379 0.49324324324324326\n",
      "Accuracy: 380 0.49324324324324326\n",
      "Accuracy: 381 0.49324324324324326\n",
      "Accuracy: 382 0.49324324324324326\n",
      "Accuracy: 383 0.49324324324324326\n",
      "Accuracy: 384 0.49324324324324326\n",
      "Accuracy: 385 0.49324324324324326\n",
      "Accuracy: 386 0.49324324324324326\n",
      "Accuracy: 387 0.49324324324324326\n",
      "Accuracy: 388 0.49324324324324326\n",
      "Accuracy: 389 0.49324324324324326\n",
      "Accuracy: 390 0.49324324324324326\n",
      "Accuracy: 391 0.49324324324324326\n",
      "Accuracy: 392 0.49324324324324326\n",
      "Accuracy: 393 0.49324324324324326\n",
      "Accuracy: 394 0.49324324324324326\n",
      "Accuracy: 395 0.49324324324324326\n",
      "Accuracy: 396 0.49324324324324326\n",
      "Accuracy: 397 0.49324324324324326\n",
      "Accuracy: 398 0.49324324324324326\n",
      "Accuracy: 399 0.49324324324324326\n",
      "Accuracy: 400 0.49324324324324326\n",
      "Accuracy: 401 0.49324324324324326\n",
      "Accuracy: 402 0.49324324324324326\n",
      "Accuracy: 403 0.49324324324324326\n",
      "Accuracy: 404 0.49324324324324326\n",
      "Accuracy: 405 0.49324324324324326\n",
      "Accuracy: 406 0.49324324324324326\n",
      "Accuracy: 407 0.49324324324324326\n",
      "Accuracy: 408 0.49324324324324326\n",
      "Accuracy: 409 0.49324324324324326\n",
      "Accuracy: 410 0.49324324324324326\n",
      "Accuracy: 411 0.49324324324324326\n",
      "Accuracy: 412 0.49324324324324326\n",
      "Accuracy: 413 0.49324324324324326\n",
      "Accuracy: 414 0.49324324324324326\n",
      "Accuracy: 415 0.49324324324324326\n",
      "Accuracy: 416 0.49324324324324326\n",
      "Accuracy: 417 0.49324324324324326\n",
      "Accuracy: 418 0.49324324324324326\n",
      "Accuracy: 419 0.49324324324324326\n",
      "Accuracy: 420 0.49324324324324326\n",
      "Accuracy: 421 0.49324324324324326\n",
      "Accuracy: 422 0.49324324324324326\n",
      "Accuracy: 423 0.49324324324324326\n",
      "Accuracy: 424 0.49324324324324326\n",
      "Accuracy: 425 0.49324324324324326\n",
      "Accuracy: 426 0.49324324324324326\n",
      "Accuracy: 427 0.49324324324324326\n",
      "Accuracy: 428 0.49324324324324326\n",
      "Accuracy: 429 0.49324324324324326\n",
      "Accuracy: 430 0.49324324324324326\n",
      "Accuracy: 431 0.49324324324324326\n",
      "Accuracy: 432 0.49324324324324326\n",
      "Accuracy: 433 0.49324324324324326\n",
      "Accuracy: 434 0.49324324324324326\n",
      "Accuracy: 435 0.49324324324324326\n",
      "Accuracy: 436 0.49324324324324326\n",
      "Accuracy: 437 0.49324324324324326\n",
      "Accuracy: 438 0.49324324324324326\n",
      "Accuracy: 439 0.49324324324324326\n",
      "Accuracy: 440 0.49324324324324326\n",
      "Accuracy: 441 0.49324324324324326\n",
      "Accuracy: 442 0.49324324324324326\n",
      "Accuracy: 443 0.49324324324324326\n",
      "Accuracy: 444 0.49324324324324326\n",
      "Accuracy: 445 0.49324324324324326\n",
      "Accuracy: 446 0.49324324324324326\n",
      "Accuracy: 447 0.49324324324324326\n",
      "Accuracy: 448 0.49324324324324326\n",
      "Accuracy: 449 0.49324324324324326\n",
      "Accuracy: 450 0.49324324324324326\n",
      "Accuracy: 451 0.49324324324324326\n",
      "Accuracy: 452 0.49324324324324326\n",
      "Accuracy: 453 0.49324324324324326\n",
      "Accuracy: 454 0.49324324324324326\n",
      "Accuracy: 455 0.49324324324324326\n",
      "Accuracy: 456 0.49324324324324326\n",
      "Accuracy: 457 0.49324324324324326\n",
      "Accuracy: 458 0.49324324324324326\n",
      "Accuracy: 459 0.49324324324324326\n",
      "Accuracy: 460 0.49324324324324326\n",
      "Accuracy: 461 0.49324324324324326\n",
      "Accuracy: 462 0.49324324324324326\n",
      "Accuracy: 463 0.49324324324324326\n",
      "Accuracy: 464 0.49324324324324326\n",
      "Accuracy: 465 0.49324324324324326\n",
      "Accuracy: 466 0.49324324324324326\n",
      "Accuracy: 467 0.49324324324324326\n",
      "Accuracy: 468 0.49324324324324326\n",
      "Accuracy: 469 0.49324324324324326\n",
      "Accuracy: 470 0.49324324324324326\n",
      "Accuracy: 471 0.49324324324324326\n",
      "Accuracy: 472 0.49324324324324326\n",
      "Accuracy: 473 0.49324324324324326\n",
      "Accuracy: 474 0.49324324324324326\n",
      "Accuracy: 475 0.49324324324324326\n",
      "Accuracy: 476 0.49324324324324326\n",
      "Accuracy: 477 0.49324324324324326\n",
      "Accuracy: 478 0.49324324324324326\n",
      "Accuracy: 479 0.49324324324324326\n",
      "Accuracy: 480 0.49324324324324326\n",
      "Accuracy: 481 0.49324324324324326\n",
      "Accuracy: 482 0.49324324324324326\n",
      "Accuracy: 483 0.49324324324324326\n",
      "Accuracy: 484 0.49324324324324326\n",
      "Accuracy: 485 0.49324324324324326\n",
      "Accuracy: 486 0.49324324324324326\n",
      "Accuracy: 487 0.49324324324324326\n",
      "Accuracy: 488 0.49324324324324326\n",
      "Accuracy: 489 0.49324324324324326\n",
      "Accuracy: 490 0.49324324324324326\n",
      "Accuracy: 491 0.49324324324324326\n",
      "Accuracy: 492 0.49324324324324326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 493 0.49324324324324326\n",
      "Accuracy: 494 0.49324324324324326\n",
      "Accuracy: 495 0.49324324324324326\n",
      "Accuracy: 496 0.49324324324324326\n",
      "Accuracy: 497 0.49324324324324326\n",
      "Accuracy: 498 0.49324324324324326\n",
      "Accuracy: 499 0.49324324324324326\n",
      "Accuracy: 500 0.49324324324324326\n",
      "Accuracy: 501 0.49324324324324326\n",
      "Accuracy: 502 0.49324324324324326\n",
      "Accuracy: 503 0.49324324324324326\n",
      "Accuracy: 504 0.49324324324324326\n",
      "Accuracy: 505 0.49324324324324326\n",
      "Accuracy: 506 0.49324324324324326\n",
      "Accuracy: 507 0.49324324324324326\n",
      "Accuracy: 508 0.49324324324324326\n",
      "Accuracy: 509 0.49324324324324326\n",
      "Accuracy: 510 0.49324324324324326\n",
      "Accuracy: 511 0.49324324324324326\n",
      "Accuracy: 512 0.49324324324324326\n",
      "Accuracy: 513 0.49324324324324326\n",
      "Accuracy: 514 0.49324324324324326\n",
      "Accuracy: 515 0.49324324324324326\n",
      "Accuracy: 516 0.49324324324324326\n",
      "Accuracy: 517 0.49324324324324326\n",
      "Accuracy: 518 0.49324324324324326\n",
      "Accuracy: 519 0.49324324324324326\n",
      "Accuracy: 520 0.49324324324324326\n",
      "Accuracy: 521 0.49324324324324326\n",
      "Accuracy: 522 0.49324324324324326\n",
      "Accuracy: 523 0.49324324324324326\n",
      "Accuracy: 524 0.49324324324324326\n",
      "Accuracy: 525 0.49324324324324326\n",
      "Accuracy: 526 0.49324324324324326\n",
      "Accuracy: 527 0.49324324324324326\n",
      "Accuracy: 528 0.49324324324324326\n",
      "Accuracy: 529 0.49324324324324326\n",
      "Accuracy: 530 0.49324324324324326\n",
      "Accuracy: 531 0.49324324324324326\n",
      "Accuracy: 532 0.49324324324324326\n",
      "Accuracy: 533 0.49324324324324326\n",
      "Accuracy: 534 0.49324324324324326\n",
      "Accuracy: 535 0.49324324324324326\n",
      "Accuracy: 536 0.49324324324324326\n",
      "Accuracy: 537 0.49324324324324326\n",
      "Accuracy: 538 0.49324324324324326\n",
      "Accuracy: 539 0.49324324324324326\n",
      "Accuracy: 540 0.49324324324324326\n",
      "Accuracy: 541 0.49324324324324326\n",
      "Accuracy: 542 0.49324324324324326\n",
      "Accuracy: 543 0.49324324324324326\n",
      "Accuracy: 544 0.49324324324324326\n",
      "Accuracy: 545 0.49324324324324326\n",
      "Accuracy: 546 0.49324324324324326\n",
      "Accuracy: 547 0.49324324324324326\n",
      "Accuracy: 548 0.49324324324324326\n",
      "Accuracy: 549 0.49324324324324326\n",
      "Accuracy: 550 0.49324324324324326\n",
      "Accuracy: 551 0.49324324324324326\n",
      "Accuracy: 552 0.49324324324324326\n",
      "Accuracy: 553 0.49324324324324326\n",
      "Accuracy: 554 0.49324324324324326\n",
      "Accuracy: 555 0.49324324324324326\n",
      "Accuracy: 556 0.49324324324324326\n",
      "Accuracy: 557 0.49324324324324326\n",
      "Accuracy: 558 0.49324324324324326\n",
      "Accuracy: 559 0.49324324324324326\n",
      "Accuracy: 560 0.49324324324324326\n",
      "Accuracy: 561 0.49324324324324326\n",
      "Accuracy: 562 0.49324324324324326\n",
      "Accuracy: 563 0.49324324324324326\n",
      "Accuracy: 564 0.49324324324324326\n",
      "Accuracy: 565 0.49324324324324326\n",
      "Accuracy: 566 0.49324324324324326\n",
      "Accuracy: 567 0.49324324324324326\n",
      "Accuracy: 568 0.49324324324324326\n",
      "Accuracy: 569 0.49324324324324326\n",
      "Accuracy: 570 0.49324324324324326\n",
      "Accuracy: 571 0.49324324324324326\n",
      "Accuracy: 572 0.49324324324324326\n",
      "Accuracy: 573 0.49324324324324326\n",
      "Accuracy: 574 0.49324324324324326\n",
      "Accuracy: 575 0.49324324324324326\n",
      "Accuracy: 576 0.49324324324324326\n",
      "Accuracy: 577 0.49324324324324326\n",
      "Accuracy: 578 0.49324324324324326\n",
      "Accuracy: 579 0.49324324324324326\n",
      "Accuracy: 580 0.49324324324324326\n",
      "Accuracy: 581 0.49324324324324326\n",
      "Accuracy: 582 0.49324324324324326\n",
      "Accuracy: 583 0.49324324324324326\n",
      "Accuracy: 584 0.49324324324324326\n",
      "Accuracy: 585 0.49324324324324326\n",
      "Accuracy: 586 0.49324324324324326\n",
      "Accuracy: 587 0.49324324324324326\n",
      "Accuracy: 588 0.49324324324324326\n",
      "Accuracy: 589 0.49324324324324326\n",
      "Accuracy: 590 0.49324324324324326\n",
      "Accuracy: 591 0.49324324324324326\n",
      "max 6\n",
      "max_val 0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "Acc = []\n",
    "for x in range(len(trainingSet)):\n",
    "    model = KNeighborsClassifier(n_neighbors=x+1)\n",
    "    model.fit(features,trainingSet['Age_Cat3'])\n",
    "    \n",
    "    predicted = []\n",
    "    for i in range(len(testSet)):\n",
    "        income = testSet.iloc[i].Income\n",
    "        region = testSet.iloc[i].Region_RC\n",
    "        occupation = testSet.iloc[i].Occupation_RC\n",
    "        education = testSet.iloc[i].Education_RC\n",
    "        gender = testSet.iloc[i].Gender_RC\n",
    "        children = testSet.iloc[i].Children\n",
    "        cars = testSet.iloc[i].Cars\n",
    "        MS = testSet.iloc[i].Marital_Status_RC\n",
    "        home = testSet.iloc[i].Home_Owner_RC\n",
    "        predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    print(\"Accuracy:\",x+1,metrics.accuracy_score(testSet.Age_Cat3, predicted))\n",
    "    Acc.append(metrics.accuracy_score(testSet.Age_Cat3, predicted))\n",
    "max_value = max(Acc)\n",
    "max_index = Acc.index(max_value)\n",
    "print('max',max_index)\n",
    "print('max_val',max_value)\n",
    "if Acc.index(max_value) == 0: #Crossvalidation is prefered so we're excluding the 1 neighbour value if it's the highest\n",
    "    Acc.remove(Acc[0])\n",
    "    max_value = max(Acc)\n",
    "    max_index = Acc.index(max_value)\n",
    "    print('max',max_index)\n",
    "    print('max_val',max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5405405405405406\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=max_index+1)\n",
    "model.fit(features,trainingSet['Age_Cat3'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    region = testSet.iloc[i].Region_RC\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Age_Cat3, predicted))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we went from 12 to 14 to 35 to 54 , all the while losing categories.\n",
    "anything <50% is useless by default but I want to refrain from losing any more categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred loc 44\n",
      "predicted [44]\n",
      "pred loc 44\n",
      "predicted [44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred loc 64\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44]\n",
      "pred loc 44\n",
      "predicted [44, 44, 44, 64, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 64, 64, 64, 44, 44, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 64, 64, 64, 44, 64, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 64, 44, 64, 44, 44, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 64, 44, 64, 44, 44, 44, 64, 44, 44, 44, 64, 44, 44, 44, 44, 64, 44, 44, 44, 44, 44]\n",
      "Accuracy: 0.5405405405405406\n",
      "i 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-51f1b136dd0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mcomplete_RC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomplete_RC\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcomplete_RC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# 0:Europe, 1:NA,2:Pacific\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m#bikes.at[bikes[bikes['Region_RC'] == 99].index[0],'Region_RC'] = mode_region\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4279\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4280\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4282\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=max_index+1)\n",
    "model.fit(features,trainingSet['Age_Cat3'])\n",
    "predicted = []\n",
    "for i in range(len(testSet)):\n",
    "    income = testSet.iloc[i].Income\n",
    "    region = testSet.iloc[i].Region_RC\n",
    "    occupation = testSet.iloc[i].Occupation_RC\n",
    "    education = testSet.iloc[i].Education_RC\n",
    "    gender = testSet.iloc[i].Gender_RC\n",
    "    children = testSet.iloc[i].Children\n",
    "    cars = testSet.iloc[i].Cars\n",
    "    MS = testSet.iloc[i].Marital_Status_RC\n",
    "    home = testSet.iloc[i].Home_Owner_RC\n",
    "    predicted.__iadd__(model.predict([[income,region,occupation,education,gender,children,cars,MS,home]])) # 0:Europe, 1:NA,2:Pacific\n",
    "    print('pred loc',predicted[i])\n",
    "    print(\"predicted\",predicted)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(testSet.Age_Cat3, predicted))\n",
    "\n",
    "    #set_region_null.at.index[i],'Region_RC' = predicted[i]\n",
    "\n",
    "for i in range(len(predicted)):\n",
    "    print(\"i\",i)\n",
    "    complete_RC.at[complete_RC[complete_RC.Age.isna()].index[0],'Age']= predicted[i] # 0:Europe, 1:NA,2:Pacific\n",
    "    #bikes.at[bikes[bikes['Region_RC'] == 99].index[0],'Region_RC'] = mode_region\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([42., 43., 60., 41., 36., 50., 33., 58., 48., 54., 55., 35., 45.,\n",
       "       38., 59., 47., 56., 34., 63., 29., 40., 44., 32., 26., 31., 62.,\n",
       "       30., 28., 65., 66., 46., 52., 39., 61., 37., 68., 51., 49., 53.,\n",
       "       27., 25., 67., 57., 70., 78., 69., 64., 89., 80., 73., 74., 71.,\n",
       "       72.])"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#after\n",
    "complete_RC.Age.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Income\n",
    "Split the null and not null values\n",
    "\n",
    "variables (Children,Cars,Region,Age,Marital_Status_RC,Gender_RC,Education_RC,Occupation_RC,Home_Owner_RC,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_RC[complete_RC.Income.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_RC_isnull = complete_RC[complete_RC['Purchased Bike'].isnull()]\n",
    "complete_RC_notnull = complete_RC[complete_RC['Purchased Bike'].notnull()]\n",
    "set_income_notnull = complete_RC_notnull[complete_RC_notnull['Income'].notnull()]\n",
    "set_income_null = complete_RC_notnull[complete_RC_notnull['Income'].isnull()]\n",
    "print(len(set_income_notnull),len(set_income_null))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_age_notnull['Income'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSet, testSet = train_test_split(set_age_notnull, test_size=0.2)\n",
    "print('trainingSet',len(trainingSet),'testSet',len(testSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features=list(zip(trainingSet['Age'],trainingSet['Occupation_RC'],trainingSet['Region_RC'],trainingSet['Education_RC'],trainingSet['Gender_RC'],trainingSet['Children'],trainingSet['Cars'],trainingSet['Marital_Status_RC'],trainingSet['Home_Owner_RC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_RC_notnull['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Children</th>\n",
       "      <th>Cars</th>\n",
       "      <th>Region</th>\n",
       "      <th>Age</th>\n",
       "      <th>Marital_Status_RC</th>\n",
       "      <th>Gender_RC</th>\n",
       "      <th>Education_RC</th>\n",
       "      <th>Occupation_RC</th>\n",
       "      <th>Home_Owner_RC</th>\n",
       "      <th>Commute_Distance_RC</th>\n",
       "      <th>Purchased Bike</th>\n",
       "      <th>Region_RC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>604</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Income  Children  Cars   Region   Age  Marital_Status_RC  Gender_RC  \\\n",
       "56    40000.0         0     0  Unknown  38.0                  0          1   \n",
       "70   120000.0         0     4  Unknown  36.0                  0          1   \n",
       "280   10000.0         3     2  Unknown  43.0                  1          0   \n",
       "424       NaN         3     2  Unknown  43.0                  1          0   \n",
       "604   40000.0         0     2  Unknown  27.0                  0          1   \n",
       "\n",
       "     Education_RC  Occupation_RC  Home_Owner_RC  Commute_Distance_RC  \\\n",
       "56              0              1              1                    1   \n",
       "70              3              2              1                   11   \n",
       "280             3              3              1                    1   \n",
       "424             3              3              1                    1   \n",
       "604             2              0              1                   10   \n",
       "\n",
       "    Purchased Bike  Region_RC  \n",
       "56             Yes          0  \n",
       "70             Yes          0  \n",
       "280             No          0  \n",
       "424             No          0  \n",
       "604             No          0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_RC[complete_RC['Region']=='Unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
